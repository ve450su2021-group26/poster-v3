{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Yahoo",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHfXOpSu58V2",
        "outputId": "32d3941e-dad4-4f2a-95c6-2a462c3628ef"
      },
      "source": [
        "!pip install -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/47/835652c7e19530973c73c65e652fc53bd05725d5a7cf9bb8706777869c1e/absl_py-0.13.0-py3-none-any.whl (132kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 26.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 51kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 71kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 92kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 102kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 112kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 122kB 10.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 10.5MB/s \n",
            "\u001b[?25hCollecting astroid==2.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/82/a61df6c2d68f3ae3ad1afa0d2e5ba5cfb7386eb80cffb453def7c5757271/astroid-2.5.6-py3-none-any.whl (219kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 3)) (1.6.3)\n",
            "Collecting boto3==1.17.103\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/6e/f19e4ee5146b16da678cc61af9cfb99a9bfe18ebed03dd0c34d89b8106b8/boto3-1.17.103-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.9MB/s \n",
            "\u001b[?25hCollecting botocore==1.20.103\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/ec/7b1657c31d73b8975e91d10780b9de750acf7e2fcd7cce6c1bd4aa3efd0d/botocore-1.20.103-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property==1.5.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 7)) (4.2.2)\n",
            "Requirement already satisfied: certifi==2021.5.30 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 8)) (2021.5.30)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 9)) (1.14.5)\n",
            "Collecting chardet==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers==1.12 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 12)) (0.4.0)\n",
            "Requirement already satisfied: google-auth==1.32.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 13)) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib==0.4.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 14)) (0.4.4)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: grpcio==1.34.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 16)) (1.34.1)\n",
            "Requirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 17)) (3.1.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 18)) (2.10)\n",
            "Requirement already satisfied: importlib-metadata==4.6.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 19)) (4.6.0)\n",
            "Collecting isort==5.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/47/0ec3ec948b7b3a0ba44e62adede4dca8b5985ba6aaee59998bed0916bd17/isort-5.8.0-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 49.2MB/s \n",
            "\u001b[?25hCollecting jmespath==0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 22)) (1.0.1)\n",
            "Requirement already satisfied: keras-nightly==2.5.0.dev2021032900 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 23)) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 24)) (1.1.2)\n",
            "Collecting lazy-object-proxy==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/b0/f055db25fd68ab4859832a887c8b304274fc12dd5a3f8e83e61250733aeb/lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 26)) (3.3.4)\n",
            "Collecting mccabe==0.6.1\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting mkl-fft==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/3e/fdc76badb389a446ab28df79f243989ec3b5219c033a55d5ac37eda3ce32/mkl_fft-1.3.0-1-cp37-cp37m-manylinux2014_x86_64.whl (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 40.6MB/s \n",
            "\u001b[?25hCollecting mkl-random\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/bf/ca70dae2036e5cf6db0d3a4d25fb62dc7e6e178ce6585544b54bf4d1f54a/mkl_random-1.2.2-1-cp37-cp37m-manylinux2014_x86_64.whl (379kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 48.0MB/s \n",
            "\u001b[?25hCollecting mkl-service==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/b2/fb25f53d275f64dcfd1634d53fbabafae3913c8c367b0337c7190ac2b188/mkl_service-2.3.0-10-cp37-cp37m-manylinux2014_x86_64.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 31)) (1.19.5)\n",
            "Requirement already satisfied: oauthlib==3.1.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 32)) (3.1.1)\n",
            "Collecting olefile==0.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 34)) (3.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 35)) (7.1.2)\n",
            "Requirement already satisfied: protobuf==3.17.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 36)) (3.17.3)\n",
            "Requirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 37)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 38)) (0.2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 39)) (2.20)\n",
            "Collecting pylint==2.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/97/a584ca733493cba7baca670800e615ced77c7b22e663e2eed6f68c931b87/pylint-2.8.3-py3-none-any.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 41)) (2.8.1)\n",
            "Collecting pytorch-pretrained-bert==0.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.4MB/s \n",
            "\u001b[?25hCollecting regex==2021.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/28/5f08d8841013ccf72cd95dfff2500fe7fb39467af12c5e7b802d8381d811/regex-2021.4.4-cp37-cp37m-manylinux2014_x86_64.whl (720kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 50.7MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 45)) (1.3.0)\n",
            "Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 46)) (4.7.2)\n",
            "Collecting s3transfer==0.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 48)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 49)) (1.4.1)\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 50)) (1.15.0)\n",
            "Requirement already satisfied: tensorboard==2.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 51)) (2.5.0)\n",
            "Requirement already satisfied: tensorboard-data-server==0.6.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 52)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 53)) (1.8.0)\n",
            "Collecting tensorboardX==2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/0b/a26bbe92667c549d39c40b80c5ddec638fbae9521f04aeef26560e07e504/tensorboardX-2.4-py2.py3-none-any.whl (124kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 55)) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator==2.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 56)) (2.5.0)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 57)) (1.1.0)\n",
            "Collecting threadpoolctl\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 59)) (0.10.2)\n",
            "Collecting torch==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/23/a4b5c189dd624411ec84613b717594a00480282b949e3448d189c4aa4e47/torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/9b/208f48d5a5013bdb0c27a84a02df4fcf5fd24ab5902667c11e554a12b681/torchvision-0.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 50.7MB/s \n",
            "\u001b[?25hCollecting tqdm==4.61.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/20/9f1e974bb4761128fc0d0a32813eaa92827309b1756c4b892d28adfb4415/tqdm-4.61.1-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25hCollecting typed-ast==1.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/b3/573d2f1fecbbe8f82a8d08172e938c247f99abe1be3bef3da2efaa3810bf/typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 64)) (3.7.4.3)\n",
            "Collecting urllib3==1.26.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/64/43575537846896abac0b15c3e5ac678d787a4021e906703f1766bfb8ea11/urllib3-1.26.6-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 56.9MB/s \n",
            "\u001b[?25hCollecting Werkzeug==2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/24/11c3ea5a7e866bf2d97f0501d0b4b1c9bbeade102bb4b588f0d2919a5212/Werkzeug-2.0.1-py3-none-any.whl (288kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 50.4MB/s \n",
            "\u001b[?25hCollecting wincertstore==0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/67/12f477fa1cc8cbcdc78027c9fb0933ad41daf2e95a29d1cc8f34fe80c692/wincertstore-0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 68)) (1.12.1)\n",
            "Requirement already satisfied: zipp==3.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 69)) (3.4.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->-r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 3)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.32.1->-r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 13)) (57.0.0)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft==1.3.0->-r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 28)) (2019.0)\n",
            "Collecting dpcpp_cpp_rt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/19/9bae82954fb3697b9c2bb8d698c2b9e9ce84612dc0a8e8abf7f2fd074944/dpcpp_cpp_rt-2021.3.0-py2.py3-none-manylinux1_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->mkl-fft==1.3.0->-r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 28)) (2021.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement intel-opencl-rt==2021.3.0 (from dpcpp_cpp_rt->mkl-fft==1.3.0->-r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 28)) (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for intel-opencl-rt==2021.3.0 (from dpcpp_cpp_rt->mkl-fft==1.3.0->-r /content/drive/MyDrive/VE450/text_processing_module/requirements.txt (line 28))\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzndsLb96_H6",
        "outputId": "de684447-d5bd-46ef-9df6-1bbfbd47f849"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "  Using cached https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/65/c5fa632ca1c243d0f757c09cc4656f361dc1a9555f0b6d442e374f7ca8f6/boto3-1.17.109-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Using cached https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.109\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/779ef784d896647f53e629143b5002adee52ea4574aa3dfaa8a9fe322c92/botocore-1.20.109-py2.py3-none-any.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 11.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "  Using cached https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.109->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.109->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.109 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.109 botocore-1.20.109 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n",
            "Collecting tensorboardX\n",
            "  Using cached https://files.pythonhosted.org/packages/99/0b/a26bbe92667c549d39c40b80c5ddec638fbae9521f04aeef26560e07e504/tensorboardX-2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGuAHwh33Ozl"
      },
      "source": [
        "utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCANW2dE3RNg"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import time\n",
        "from sklearn import metrics\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"单句子分类的 Example 类\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, idx, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.idx = idx\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
        "                                 tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\n",
        "    Args:\n",
        "        examples: InputExample, 表示样本集\n",
        "        label_list: 标签列表\n",
        "        max_seq_length: 句子最大长度\n",
        "        tokenizer： 分词器\n",
        "    Returns:\n",
        "        features: InputFeatures, 表示样本转化后信息 \n",
        "    \"\"\"\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            print(\"Writing example {} of {}\".format(ex_index, len(examples)))\n",
        "\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)  # 分词\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)  # 分词\n",
        "            # “-3” 是因为句子中有[CLS], [SEP], [SEP] 三个标识，可参见论文\n",
        "            # [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # \"- 2\" 是因为句子中有[CLS], [SEP] 两个标识，可参见论文\n",
        "            # [CLS] the dog is hairy . [SEP]\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # [CLS] 可以视作是保存句子全局向量信息\n",
        "        # [SEP] 用于区分句子，使得模型能够更好的把握句子信息\n",
        "\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)  # 句子标识，0表示是第一个句子，1表示是第二个句子，参见论文\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)  # 将词转化为对应词表中的id\n",
        "\n",
        "        # input_mask: 1 表示真正的 tokens， 0 表示是 padding tokens\n",
        "        input_mask = [1] * len(input_ids)\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "\n",
        "        try:\n",
        "            label_id = label_map[example.label]\n",
        "        except:\n",
        "            print(example.label)\n",
        "            continue\n",
        "        idx = int(example.guid)\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(idx=idx, \n",
        "                          input_ids=input_ids,\n",
        "                          input_mask=input_mask,\n",
        "                          segment_ids=segment_ids,\n",
        "                          label_id=label_id))\n",
        "    return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\" 截断句子a和句子b，使得二者之和不超过 max_length \"\"\"\n",
        "\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "\n",
        "def convert_features_to_tensors(features, batch_size, data_type):\n",
        "    \"\"\" 将 features 转化为 tensor，并塞入迭代器\n",
        "    Args:\n",
        "        features: InputFeatures, 样本 features 信息\n",
        "        batch_size: batch 大小\n",
        "    Returns:\n",
        "        dataloader: 以 batch_size 为基础的迭代器\n",
        "    \"\"\"\n",
        "    all_idx_ids = torch.tensor(\n",
        "        [f.idx for f in features], dtype=torch.long)\n",
        "    all_input_ids = torch.tensor(\n",
        "        [f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor(\n",
        "        [f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor(\n",
        "        [f.segment_ids for f in features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor(\n",
        "        [f.label_id for f in features], dtype=torch.long)\n",
        "\n",
        "    data = TensorDataset(all_idx_ids, all_input_ids, all_input_mask,\n",
        "                         all_segment_ids, all_label_ids)\n",
        "\n",
        "    sampler = RandomSampler(data)\n",
        "    if data_type == \"test_verbose\":\n",
        "        dataloader = DataLoader(data, shuffle=False, batch_size=batch_size)\n",
        "    elif data_type == \"test\":\n",
        "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)        \n",
        "    else:\n",
        "        dataloader = DataLoader(data, sampler=sampler,\n",
        "                                batch_size=batch_size, drop_last=True)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def get_device(gpu_id):\n",
        "    device = torch.device(\"cuda:\" + str(gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"device is cuda, # cuda is: \", n_gpu)\n",
        "    else:\n",
        "        print(\"device is cpu, not recommend\")\n",
        "    return device, n_gpu\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "def classifiction_metric(preds, labels, label_list):\n",
        "    \"\"\" 分类任务的评价指标， 传入的数据需要是 numpy 类型的 \"\"\"\n",
        "\n",
        "    acc = metrics.accuracy_score(labels, preds)\n",
        "\n",
        "    labels_list = [i for i in range(len(label_list))]\n",
        "\n",
        "    report = metrics.classification_report(labels, preds, labels=labels_list, target_names=label_list, digits=5, output_dict=True)\n",
        "    \n",
        "    if len(label_list) > 2:\n",
        "        auc = 0.5\n",
        "    else:\n",
        "        auc = metrics.roc_auc_score(labels, preds)\n",
        "    return acc, report, auc\n",
        "\n",
        "\n",
        "def read_tsv(filename):\n",
        "    with open(filename, \"r\", encoding='latin-1') as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\")\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "def load_tsv_dataset(filename, set_type):\n",
        "    \"\"\"\n",
        "    文件内数据格式: sentence  label\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    lines = read_tsv(filename)\n",
        "    for (i, line) in enumerate(lines):\n",
        "        guid = i\n",
        "        text_a = line[0]\n",
        "        label = line[1]\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "    return examples\n",
        "\n",
        "\n",
        "def load_data(data_dir, tokenizer, max_length, batch_size, data_type, label_list, format_type=0):\n",
        "    if format_type == 0:\n",
        "        load_func = load_tsv_dataset\n",
        "\n",
        "    if data_type == \"train\":\n",
        "        train_file = os.path.join(data_dir, 'train.tsv')\n",
        "        examples = load_func(train_file, data_type)\n",
        "    elif data_type == \"dev\":\n",
        "        dev_file = os.path.join(data_dir, 'dev.tsv')\n",
        "        examples = load_func(dev_file, data_type)\n",
        "    elif data_type == \"test\" or data_type == \"test_verbose\":\n",
        "        test_file = os.path.join(data_dir, 'test.tsv')\n",
        "        examples = load_func(test_file, data_type)\n",
        "    else:\n",
        "        raise RuntimeError(\"should be train or dev or test or test verbose\")\n",
        "\n",
        "    features = convert_examples_to_features(\n",
        "        examples, label_list, max_length, tokenizer)\n",
        "\n",
        "    dataloader = convert_features_to_tensors(features, batch_size, data_type)\n",
        "\n",
        "    examples_len = len(examples)\n",
        "\n",
        "    return dataloader, examples\n",
        "\n",
        "\n",
        "# coding=utf-8\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrOPEXka2_CO"
      },
      "source": [
        "model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNVGjW3i3BAX"
      },
      "source": [
        "# coding=utf-8\n",
        "\n",
        "import argparse\n",
        "\n",
        "\n",
        "def get_args(data_dir, output_dir, cache_dir, bert_vocab_file, bert_model_dir, log_dir):\n",
        "\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='BERT Baseline')\n",
        "\n",
        "    parser.add_argument(\"--model_name\", default=\"BertBasic\", type=str, help=\"the name of model\")\n",
        "\n",
        "    parser.add_argument(\"--save_name\", default=\"BertBasic\",type=str, help=\"the name file of model\")\n",
        "\n",
        "    # 文件路径：数据目录， 缓存目录\n",
        "    parser.add_argument(\"--data_dir\",\n",
        "                        default=data_dir,\n",
        "                        type=str,\n",
        "                        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
        "    \n",
        "    parser.add_argument(\"--output_dir\",\n",
        "                        default=output_dir + \"BertBasic/\",\n",
        "                        type=str,\n",
        "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
        "\n",
        "    parser.add_argument(\"--cache_dir\", \n",
        "                        default=cache_dir + \"BertBasic/\",\n",
        "                        type=str,\n",
        "                        help=\"缓存目录，主要用于模型缓存\")\n",
        "    \n",
        "    parser.add_argument(\"--log_dir\",\n",
        "                        default=log_dir + \"BertBasic/\",\n",
        "                        type=str,\n",
        "                        help=\"日志目录，主要用于 tensorboard 分析\")\n",
        "\n",
        "\n",
        "    parser.add_argument(\"--bert_vocab_file\",\n",
        "                         default=bert_vocab_file,\n",
        "                         type=str)\n",
        "    parser.add_argument(\"--bert_model_dir\",\n",
        "                         default=bert_model_dir,\n",
        "                         type=str)\n",
        "\n",
        "    parser.add_argument('--seed',\n",
        "                        type=int,\n",
        "                        default=42,\n",
        "                        help=\"随机种子 for initialization\")\n",
        "\n",
        "    # 文本预处理参数\n",
        "    parser.add_argument(\"--do_lower_case\",\n",
        "                        default=True,\n",
        "                        type=bool,\n",
        "                        help=\"Set this flag if you are using an uncased model.\")\n",
        "\n",
        "    parser.add_argument(\"--max_seq_length\",\n",
        "                        default=512,\n",
        "                        type=int,\n",
        "                        help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
        "                             \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
        "                             \"than this will be padded.\")\n",
        "\n",
        "\n",
        "    # 训练参数\n",
        "    parser.add_argument(\"--train_batch_size\",\n",
        "                        default=64,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for training.\")\n",
        "\n",
        "    parser.add_argument(\"--dev_batch_size\",\n",
        "                        default=8,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for dev.\")\n",
        "    parser.add_argument(\"--test_batch_size\",\n",
        "                        default=32,\n",
        "                        type=int,\n",
        "                        help=\"Total batch size for test.\")\n",
        "\n",
        "    parser.add_argument(\"--do_train\",\n",
        "                        action='store_true',\n",
        "                        help=\"Whether to run training.\")\n",
        "\n",
        "\n",
        "    parser.add_argument(\"--do_test_verbose\",\n",
        "                        action='store_true',\n",
        "                        help=\"Whether to run testing in verbose mode.\")              \n",
        "\n",
        "    parser.add_argument(\"--num_train_epochs\",\n",
        "                        default=1.0,\n",
        "                        type=float,\n",
        "                        help=\"Total number of training epochs to perform.\")\n",
        "    parser.add_argument(\"--warmup_proportion\",\n",
        "                        default=0.1,\n",
        "                        type=float,\n",
        "                        help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
        "                        \"E.g., 0.1 = 10%% of training.\")\n",
        "    # optimizer 参数\n",
        "    parser.add_argument(\"--learning_rate\", \n",
        "                        default=5e-5,\n",
        "                        type=float,\n",
        "                        help=\"Adam 的 学习率\")\n",
        "\n",
        "    # 梯度累积\n",
        "    parser.add_argument('--gradient_accumulation_steps',\n",
        "                        type=int,\n",
        "                        default=1,\n",
        "                        help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
        "\n",
        "    parser.add_argument('--print_step',\n",
        "                        type=int,\n",
        "                        default=50,\n",
        "                        help=\"多少步进行模型保存以及日志信息写入\")\n",
        "     \n",
        "    parser.add_argument(\"--early_stop\", type=int, default=50, help=\"提前终止，多少次dev loss 连续增大，就不再训练\")\n",
        "\n",
        "\n",
        "    parser.add_argument(\"--gpu_ids\", type=str, default=\"0\", help=\"gpu 的设备id\")\n",
        "    config = parser.parse_args()\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "# coding=utf-8\n",
        "\n",
        "from pytorch_pretrained_bert.modeling import BertModel, BertPreTrainedModel\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "class BertBasic(BertPreTrainedModel):\n",
        "\n",
        "    def __init__(self, config, num_labels):\n",
        "        super(BertBasic, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            input_ids: 词对应的 id\n",
        "            token_type_ids: 区分句子，0 为第一句，1表示第二句\n",
        "            attention_mask: 区分 padding 与 token， 1表示是token，0 为padding\n",
        "        \"\"\"\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        # pooled_output: [batch_size, dim=768]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        logits = self.classifier(pooled_output)\n",
        "        # logits: [batch_size, output_dim=2]\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yExtV6rw3mff"
      },
      "source": [
        "train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqKsfqLJ3nxV"
      },
      "source": [
        "# coding=utf-8\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def train(epoch_num, n_gpu, model, train_dataloader, dev_dataloader, \n",
        "optimizer, criterion, gradient_accumulation_steps, device, label_list, \n",
        "output_model_file, output_config_file, log_dir, print_step, early_stop):\n",
        "    \"\"\" 模型训练过程\n",
        "    Args: \n",
        "        epoch_num: epoch 数量\n",
        "        n_gpu: 使用的 gpu 数量\n",
        "        train_dataloader: 训练数据的Dataloader\n",
        "        dev_dataloader: 测试数据的 Dataloader\n",
        "        optimizer: 优化器\n",
        "        criterion： 损失函数定义\n",
        "        gradient_accumulation_steps: 梯度积累\n",
        "        device: 设备，cuda， cpu\n",
        "        label_list: 分类的标签数组\n",
        "        output_model_file: 用于保存 Bert 模型\n",
        "        output_config_file: 用于 Bert 配置文件\n",
        "        log_dir: tensorboard 读取的日志目录，用于后续分析\n",
        "        print_step: 多少步保存一次模型，日志等信息\n",
        "        early_stop: 提前终止\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "    early_stop_times = 0\n",
        "\n",
        "    writer = SummaryWriter(\n",
        "        log_dir=os.path.join(os.path.abspath(log_dir),time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(time.time()))).replace('/','\\\\'))\n",
        "\n",
        "\n",
        "    best_dev_loss = float('inf')\n",
        "    best_auc = 0\n",
        "    best_acc = 0\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(int(epoch_num)):\n",
        "\n",
        "        if early_stop_times >= early_stop:\n",
        "            break\n",
        "\n",
        "        print(f'---------------- Epoch: {epoch+1:02} ----------')\n",
        "\n",
        "        epoch_loss = 0\n",
        "\n",
        "        train_steps = 0\n",
        "\n",
        "        all_preds = np.array([], dtype=int)\n",
        "        all_labels = np.array([], dtype=int)\n",
        "\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "            model.train()\n",
        "            \n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            _, input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "            logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "            loss = criterion(logits.view(-1, len(label_list)), label_ids.view(-1))\n",
        "\n",
        "            \"\"\" 修正 loss \"\"\"\n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu.\n",
        "            if gradient_accumulation_steps > 1:\n",
        "                loss = loss / gradient_accumulation_steps\n",
        "            \n",
        "            train_steps += 1\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # 用于画图和分析的数据\n",
        "            epoch_loss += loss.item()\n",
        "            preds = logits.detach().cpu().numpy()\n",
        "            outputs = np.argmax(preds, axis=1)\n",
        "            all_preds = np.append(all_preds, outputs)\n",
        "            label_ids = label_ids.to('cpu').numpy()\n",
        "            all_labels = np.append(all_labels, label_ids)\n",
        "\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "            \n",
        "                if global_step % print_step == 0 and global_step != 0:\n",
        "\n",
        "                    \"\"\" 打印Train此时的信息 \"\"\"\n",
        "                    train_loss = epoch_loss / train_steps\n",
        "                    train_acc, train_report, train_auc = classifiction_metric(all_preds, all_labels, label_list)\n",
        "\n",
        "                    dev_loss, dev_acc, dev_report, dev_auc = evaluate(model, dev_dataloader, criterion, device, label_list)\n",
        "\n",
        "                    c = global_step // print_step\n",
        "                    writer.add_scalar(\"loss/train\", train_loss, c)\n",
        "                    writer.add_scalar(\"loss/dev\", dev_loss, c)\n",
        "\n",
        "                    writer.add_scalar(\"acc/train\", train_acc, c)\n",
        "                    writer.add_scalar(\"acc/dev\", dev_acc, c)\n",
        "\n",
        "                    writer.add_scalar(\"auc/train\", train_auc, c)\n",
        "                    writer.add_scalar(\"auc/dev\", dev_auc, c)\n",
        "\n",
        "                    for label in label_list:\n",
        "                        writer.add_scalar(label + \":\" + \"f1/train\", train_report[label]['f1-score'], c)\n",
        "                        writer.add_scalar(label + \":\" + \"f1/dev\",\n",
        "                                        dev_report[label]['f1-score'], c)\n",
        "\n",
        "                    print_list = ['macro avg', 'weighted avg']\n",
        "                    for label in print_list:\n",
        "                        writer.add_scalar(label + \":\" + \"f1/train\",\n",
        "                                        train_report[label]['f1-score'], c)\n",
        "                        writer.add_scalar(label + \":\" + \"f1/dev\",\n",
        "                                        dev_report[label]['f1-score'], c)\n",
        "                    \n",
        "                    # # 以损失取优\n",
        "                    # if dev_loss < best_dev_loss:\n",
        "                    #     best_dev_loss = dev_loss\n",
        "                    \n",
        "                    # 以 acc 取优\n",
        "                    if dev_acc > best_acc:\n",
        "                        best_acc = dev_acc\n",
        "                        \n",
        "                    # 以 auc 取优\n",
        "                    # if dev_auc > best_auc:\n",
        "                    #     best_auc = dev_auc\n",
        "\n",
        "\n",
        "                        model_to_save = model.module if hasattr(\n",
        "                            model, 'module') else model\n",
        "                        torch.save(model_to_save.state_dict(), output_model_file)\n",
        "                        with open(output_config_file, 'w') as f:\n",
        "                            f.write(model_to_save.config.to_json_string())\n",
        "\n",
        "                        early_stop_times = 0\n",
        "                    else:\n",
        "                        early_stop_times += 1\n",
        "\n",
        "    writer.close()\n",
        "                    \n",
        "\n",
        "def evaluate(model, dataloader, criterion, device, label_list):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = np.array([], dtype=int)\n",
        "    all_labels = np.array([], dtype=int)\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, input_ids, input_mask, segment_ids, label_ids in tqdm(dataloader, desc=\"Eval\"):\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "        loss = criterion(logits.view(-1, len(label_list)), label_ids.view(-1))\n",
        "\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "        outputs = np.argmax(preds, axis=1)\n",
        "        all_preds = np.append(all_preds, outputs)\n",
        "\n",
        "        label_ids = label_ids.to('cpu').numpy()\n",
        "        all_labels = np.append(all_labels, label_ids)\n",
        "\n",
        "        epoch_loss += loss.mean().item()\n",
        "\n",
        "    acc, report, auc = classifiction_metric(all_preds, all_labels, label_list)\n",
        "    return epoch_loss/len(dataloader), acc, report, auc\n",
        "\n",
        "\n",
        "def evaluate_save(model, dataloader, criterion, device, label_list):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = np.array([], dtype=int)\n",
        "    all_labels = np.array([], dtype=int)\n",
        "    all_idxs = np.array([], dtype=int)\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for idxs, input_ids, input_mask, segment_ids, label_ids in tqdm(dataloader, desc=\"Eval\"):\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
        "        loss = criterion(logits.view(-1, len(label_list)), label_ids.view(-1))\n",
        "\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "        outputs = np.argmax(preds, axis=1)\n",
        "        all_preds = np.append(all_preds, outputs)\n",
        "\n",
        "        label_ids = label_ids.to('cpu').numpy()\n",
        "        all_labels = np.append(all_labels, label_ids)\n",
        "\n",
        "        idxs = idxs.detach().cpu().numpy()\n",
        "        all_idxs = np.append(all_idxs, idxs)\n",
        "\n",
        "        epoch_loss += loss.mean().item()\n",
        "\n",
        "    acc, report, auc = classifiction_metric(all_preds, all_labels, label_list)\n",
        "    return epoch_loss/len(dataloader), acc, report, auc, all_idxs, all_labels, all_preds\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYuucuo87Nh3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goBjGarq2rZx"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9q9uobG21Nd"
      },
      "source": [
        "# coding=utf-8\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertConfig, WEIGHTS_NAME, CONFIG_NAME\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "\n",
        "def main(config, model_times, label_list, label_names):\n",
        "\n",
        "    if not os.path.exists(config.output_dir + model_times):\n",
        "        os.makedirs(config.output_dir + model_times)\n",
        "\n",
        "    if not os.path.exists(config.cache_dir + model_times):\n",
        "        os.makedirs(config.cache_dir + model_times)\n",
        "\n",
        "    # Bert 模型输出文件\n",
        "    output_model_file = os.path.join(config.output_dir, model_times, WEIGHTS_NAME).replace('\\\\','/')  \n",
        "    output_config_file = os.path.join(config.output_dir, model_times,CONFIG_NAME).replace('\\\\','/')\n",
        "\n",
        "    # 设备准备\n",
        "    gpu_ids = [int(device_id) for device_id in config.gpu_ids.split()]\n",
        "    device, n_gpu = get_device(gpu_ids[0])  \n",
        "    if n_gpu > 1:\n",
        "        n_gpu = len(gpu_ids)\n",
        "\n",
        "    config.train_batch_size = config.train_batch_size // config.gradient_accumulation_steps\n",
        "\n",
        "    # 设定随机种子 \n",
        "    random.seed(config.seed)\n",
        "    np.random.seed(config.seed)\n",
        "    torch.manual_seed(config.seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(config.seed)\n",
        "\n",
        "    # 数据准备\n",
        "    tokenizer = BertTokenizer.from_pretrained(\n",
        "        config.bert_vocab_file, do_lower_case=config.do_lower_case)  # 分词器选择\n",
        "\n",
        "    num_labels = len(label_list)\n",
        "\n",
        "    # Train and dev\n",
        "    if config.do_train:\n",
        "\n",
        "        train_dataloader, examples = load_data(\n",
        "            config.data_dir, tokenizer, config.max_seq_length, config.train_batch_size, \"train\", label_list)\n",
        "        train_examples_len = len(examples)\n",
        "        dev_dataloader, _ = load_data(\n",
        "            config.data_dir, tokenizer, config.max_seq_length, config.dev_batch_size, \"dev\", label_list)\n",
        "        \n",
        "        num_train_optimization_steps = int(\n",
        "            train_examples_len / config.train_batch_size / config.gradient_accumulation_steps) * config.num_train_epochs\n",
        "        \n",
        "        # 模型准备\n",
        "        print(\"model name is {}\".format(config.model_name))\n",
        "\n",
        "        model = BertBasic.from_pretrained(\n",
        "                config.bert_model_dir, cache_dir=config.cache_dir, num_labels=num_labels)\n",
        "\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        if n_gpu > 1:\n",
        "            model = torch.nn.DataParallel(model,device_ids=gpu_ids)\n",
        "\n",
        "        \"\"\" 优化器准备 \"\"\"\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(\n",
        "                nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "            {'params': [p for n, p in param_optimizer if any(\n",
        "                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                             lr=config.learning_rate,\n",
        "                             warmup=config.warmup_proportion,\n",
        "                             t_total=num_train_optimization_steps)\n",
        "\n",
        "        \"\"\" 损失函数准备 \"\"\"\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        criterion = criterion.to(device)\n",
        "\n",
        "        train(config.num_train_epochs, n_gpu, model, train_dataloader, dev_dataloader, optimizer,\n",
        "              criterion, config.gradient_accumulation_steps, device, label_list, output_model_file, output_config_file, config.log_dir, config.print_step, config.early_stop)\n",
        "\n",
        "    \"\"\" Test \"\"\"\n",
        "\n",
        "    # test 数据\n",
        "    if config.do_test_verbose:\n",
        "        test_dataloader, examples = load_data(\n",
        "            config.data_dir, tokenizer, config.max_seq_length, config.test_batch_size, \"test_verbose\", label_list)\n",
        "    else:\n",
        "        test_dataloader, examples = load_data(\n",
        "            config.data_dir, tokenizer, config.max_seq_length, config.test_batch_size, \"test\", label_list)\n",
        "    # 加载模型 \n",
        "    bert_config = BertConfig(output_config_file)\n",
        "\n",
        "\n",
        "    model = BertBasic(bert_config, num_labels=num_labels)\n",
        "\n",
        "    model.load_state_dict(torch.load(output_model_file))\n",
        "    model.to(device)\n",
        "\n",
        "    # 损失函数准备\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    # test the model\n",
        "    test_loss, test_acc, test_report, test_auc, all_idx, all_labels, all_preds = evaluate_save(\n",
        "        model, test_dataloader, criterion, device, label_list)\n",
        "    \n",
        "\n",
        "    print(\"-------------- Test -------------\")\n",
        "    print(f'\\t  Loss: {test_loss: .3f} | Acc: {test_acc*100: .3f} % | AUC:{test_auc}')\n",
        "\n",
        "    for label in label_list:\n",
        "        print('\\t {}: Precision: {} | recall: {} | f1 score: {}'.format(\n",
        "            label, test_report[label]['precision'], test_report[label]['recall'], test_report[label]['f1-score']))\n",
        "    print_list = ['macro avg', 'weighted avg']\n",
        "\n",
        "    for label in print_list:\n",
        "        print('\\t {}: Precision: {} | recall: {} | f1 score: {}'.format(\n",
        "            label, test_report[label]['precision'], test_report[label]['recall'], test_report[label]['f1-score']))\n",
        "\n",
        "    if config.do_test_verbose:\n",
        "        index_range = min(len(all_labels), 10)\n",
        "        index_list = [random.randint(0, len(all_labels)-1) for i in range(index_range)]\n",
        "        for index in index_list:\n",
        "            print(\"====================\")\n",
        "            print(\"CORRECT CLASS: {}, PREDICTED CLASS: {}\".format(label_names[all_labels[index]], label_names[all_preds[index]]))\n",
        "            print(\"SENTENCE INPUT: {}\".format(examples[index].text_a))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMQ7aMdJ2kLN"
      },
      "source": [
        "run.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_SF_AqlzSO-",
        "outputId": "e50fa0ba-5fc0-4388-c416-4b3b04cb298e"
      },
      "source": [
        "root_path = \"/content/drive/MyDrive/VE450/text_processing_module/\"\n",
        "\n",
        "class args:\n",
        "  def __init__(self):\n",
        "    args.bert_model_dir = root_path+\"parameters/bert-base-uncased\"\n",
        "    args.bert_vocab_file = root_path+\"parameters/bert-base-uncased-vocab.txt\"\n",
        "    args.cache_dir = root_path+\".yahoo_answers_cache\"\n",
        "    args.data_dir = root_path+\"datasets/yahoo_answers_small\"\n",
        "    args.dev_batch_size = 8\n",
        "    args.do_lower_case = True\n",
        "    args.do_test_verbose = False\n",
        "    args.do_train = True\n",
        "    args.early_stop = 50\n",
        "    args.gpu_ids = '0'\n",
        "    args.gradient_accumulation_steps = 1\n",
        "    args.learning_rate = 5e-05\n",
        "    args.log_dir = root_path+\".yahoo_answers_log/\"\n",
        "    args.max_seq_length = 100\n",
        "    args.model_name = \"BertBasic\"\n",
        "    args.num_train_epochs = 1.0\n",
        "    args.output_dir = root_path+\".yahoo_answers_output/\"\n",
        "    args.print_step = 50\n",
        "    args.save_name = \"BertBasic\"\n",
        "    args.seed = 42\n",
        "    args.test_batch_size = 32\n",
        "    args.train_batch_size = 64\n",
        "    args.warmup_proportion = 0.1\n",
        "\n",
        "label_list = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
        "label_names = [\"Society & Culture\", \"Science & Mathematics\", \"Health\", \"Education & Reference\", \"Computers & Internet\", \"Sports\",\n",
        "    \"Business & Finance\",  \"Entertainment & Music\", \"Family & Relationships\", \"Politics & Government\"]\n",
        "\n",
        "config = args()\n",
        "main(config, config.save_name, label_list, label_names)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device is cuda, # cuda is:  1\n",
            "Writing example 0 of 22446\n",
            "Writing example 10000 of 22446\n",
            "Writing example 20000 of 22446\n",
            "Writing example 0 of 22446\n",
            "Writing example 10000 of 22446\n",
            "Writing example 20000 of 22446\n",
            "model name is BertBasic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rIteration:   0%|          | 0/350 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "---------------- Epoch: 01 ----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "Iteration:  14%|█▍        | 49/350 [01:02<06:34,  1.31s/it]\n",
            "Eval:   0%|          | 0/2805 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   0%|          | 2/2805 [00:00<02:33, 18.28it/s]\u001b[A\n",
            "Eval:   0%|          | 4/2805 [00:00<02:37, 17.79it/s]\u001b[A\n",
            "Eval:   0%|          | 6/2805 [00:00<02:41, 17.33it/s]\u001b[A\n",
            "Eval:   0%|          | 8/2805 [00:00<02:41, 17.28it/s]\u001b[A\n",
            "Eval:   0%|          | 10/2805 [00:00<02:42, 17.21it/s]\u001b[A\n",
            "Eval:   0%|          | 12/2805 [00:00<02:43, 17.11it/s]\u001b[A\n",
            "Eval:   0%|          | 14/2805 [00:00<02:44, 17.00it/s]\u001b[A\n",
            "Eval:   1%|          | 16/2805 [00:00<02:50, 16.40it/s]\u001b[A\n",
            "Eval:   1%|          | 18/2805 [00:01<02:48, 16.49it/s]\u001b[A\n",
            "Eval:   1%|          | 20/2805 [00:01<02:47, 16.65it/s]\u001b[A\n",
            "Eval:   1%|          | 22/2805 [00:01<02:47, 16.63it/s]\u001b[A\n",
            "Eval:   1%|          | 24/2805 [00:01<02:48, 16.49it/s]\u001b[A\n",
            "Eval:   1%|          | 26/2805 [00:01<02:47, 16.61it/s]\u001b[A\n",
            "Eval:   1%|          | 28/2805 [00:01<02:46, 16.67it/s]\u001b[A\n",
            "Eval:   1%|          | 30/2805 [00:01<02:46, 16.69it/s]\u001b[A\n",
            "Eval:   1%|          | 32/2805 [00:01<02:48, 16.45it/s]\u001b[A\n",
            "Eval:   1%|          | 34/2805 [00:02<02:48, 16.46it/s]\u001b[A\n",
            "Eval:   1%|▏         | 36/2805 [00:02<02:48, 16.47it/s]\u001b[A\n",
            "Eval:   1%|▏         | 38/2805 [00:02<02:47, 16.49it/s]\u001b[A\n",
            "Eval:   1%|▏         | 40/2805 [00:02<02:48, 16.43it/s]\u001b[A\n",
            "Eval:   1%|▏         | 42/2805 [00:02<02:47, 16.49it/s]\u001b[A\n",
            "Eval:   2%|▏         | 44/2805 [00:02<02:47, 16.53it/s]\u001b[A\n",
            "Eval:   2%|▏         | 46/2805 [00:02<02:48, 16.41it/s]\u001b[A\n",
            "Eval:   2%|▏         | 48/2805 [00:02<02:48, 16.33it/s]\u001b[A\n",
            "Eval:   2%|▏         | 50/2805 [00:03<02:48, 16.36it/s]\u001b[A\n",
            "Eval:   2%|▏         | 52/2805 [00:03<02:47, 16.41it/s]\u001b[A\n",
            "Eval:   2%|▏         | 54/2805 [00:03<02:47, 16.46it/s]\u001b[A\n",
            "Eval:   2%|▏         | 56/2805 [00:03<02:46, 16.49it/s]\u001b[A\n",
            "Eval:   2%|▏         | 58/2805 [00:03<02:45, 16.55it/s]\u001b[A\n",
            "Eval:   2%|▏         | 60/2805 [00:03<02:46, 16.47it/s]\u001b[A\n",
            "Eval:   2%|▏         | 62/2805 [00:03<02:46, 16.43it/s]\u001b[A\n",
            "Eval:   2%|▏         | 64/2805 [00:03<02:46, 16.49it/s]\u001b[A\n",
            "Eval:   2%|▏         | 66/2805 [00:03<02:47, 16.32it/s]\u001b[A\n",
            "Eval:   2%|▏         | 68/2805 [00:04<02:47, 16.36it/s]\u001b[A\n",
            "Eval:   2%|▏         | 70/2805 [00:04<02:46, 16.42it/s]\u001b[A\n",
            "Eval:   3%|▎         | 72/2805 [00:04<02:45, 16.54it/s]\u001b[A\n",
            "Eval:   3%|▎         | 74/2805 [00:04<02:45, 16.50it/s]\u001b[A\n",
            "Eval:   3%|▎         | 76/2805 [00:04<02:45, 16.48it/s]\u001b[A\n",
            "Eval:   3%|▎         | 78/2805 [00:04<02:46, 16.33it/s]\u001b[A\n",
            "Eval:   3%|▎         | 80/2805 [00:04<02:45, 16.42it/s]\u001b[A\n",
            "Eval:   3%|▎         | 82/2805 [00:04<02:46, 16.39it/s]\u001b[A\n",
            "Eval:   3%|▎         | 84/2805 [00:05<02:45, 16.46it/s]\u001b[A\n",
            "Eval:   3%|▎         | 86/2805 [00:05<02:45, 16.47it/s]\u001b[A\n",
            "Eval:   3%|▎         | 88/2805 [00:05<02:45, 16.45it/s]\u001b[A\n",
            "Eval:   3%|▎         | 90/2805 [00:05<02:45, 16.45it/s]\u001b[A\n",
            "Eval:   3%|▎         | 92/2805 [00:05<02:45, 16.38it/s]\u001b[A\n",
            "Eval:   3%|▎         | 94/2805 [00:05<02:44, 16.43it/s]\u001b[A\n",
            "Eval:   3%|▎         | 96/2805 [00:05<02:45, 16.40it/s]\u001b[A\n",
            "Eval:   3%|▎         | 98/2805 [00:05<02:44, 16.45it/s]\u001b[A\n",
            "Eval:   4%|▎         | 100/2805 [00:06<02:44, 16.49it/s]\u001b[A\n",
            "Eval:   4%|▎         | 102/2805 [00:06<02:44, 16.47it/s]\u001b[A\n",
            "Eval:   4%|▎         | 104/2805 [00:06<02:43, 16.52it/s]\u001b[A\n",
            "Eval:   4%|▍         | 106/2805 [00:06<02:44, 16.39it/s]\u001b[A\n",
            "Eval:   4%|▍         | 108/2805 [00:06<02:44, 16.44it/s]\u001b[A\n",
            "Eval:   4%|▍         | 110/2805 [00:06<02:44, 16.41it/s]\u001b[A\n",
            "Eval:   4%|▍         | 112/2805 [00:06<02:44, 16.33it/s]\u001b[A\n",
            "Eval:   4%|▍         | 114/2805 [00:06<02:44, 16.41it/s]\u001b[A\n",
            "Eval:   4%|▍         | 116/2805 [00:07<02:43, 16.44it/s]\u001b[A\n",
            "Eval:   4%|▍         | 118/2805 [00:07<02:43, 16.48it/s]\u001b[A\n",
            "Eval:   4%|▍         | 120/2805 [00:07<02:43, 16.43it/s]\u001b[A\n",
            "Eval:   4%|▍         | 122/2805 [00:07<02:44, 16.35it/s]\u001b[A\n",
            "Eval:   4%|▍         | 124/2805 [00:07<02:42, 16.46it/s]\u001b[A\n",
            "Eval:   4%|▍         | 126/2805 [00:07<02:43, 16.43it/s]\u001b[A\n",
            "Eval:   5%|▍         | 128/2805 [00:07<02:44, 16.31it/s]\u001b[A\n",
            "Eval:   5%|▍         | 130/2805 [00:07<02:45, 16.14it/s]\u001b[A\n",
            "Eval:   5%|▍         | 132/2805 [00:08<02:45, 16.11it/s]\u001b[A\n",
            "Eval:   5%|▍         | 134/2805 [00:08<02:44, 16.21it/s]\u001b[A\n",
            "Eval:   5%|▍         | 136/2805 [00:08<02:43, 16.33it/s]\u001b[A\n",
            "Eval:   5%|▍         | 138/2805 [00:08<02:42, 16.44it/s]\u001b[A\n",
            "Eval:   5%|▍         | 140/2805 [00:08<02:41, 16.50it/s]\u001b[A\n",
            "Eval:   5%|▌         | 142/2805 [00:08<02:41, 16.46it/s]\u001b[A\n",
            "Eval:   5%|▌         | 144/2805 [00:08<02:40, 16.55it/s]\u001b[A\n",
            "Eval:   5%|▌         | 146/2805 [00:08<02:41, 16.46it/s]\u001b[A\n",
            "Eval:   5%|▌         | 148/2805 [00:08<02:41, 16.49it/s]\u001b[A\n",
            "Eval:   5%|▌         | 150/2805 [00:09<02:42, 16.29it/s]\u001b[A\n",
            "Eval:   5%|▌         | 152/2805 [00:09<02:42, 16.29it/s]\u001b[A\n",
            "Eval:   5%|▌         | 154/2805 [00:09<02:42, 16.33it/s]\u001b[A\n",
            "Eval:   6%|▌         | 156/2805 [00:09<02:40, 16.46it/s]\u001b[A\n",
            "Eval:   6%|▌         | 158/2805 [00:09<02:43, 16.23it/s]\u001b[A\n",
            "Eval:   6%|▌         | 160/2805 [00:09<02:41, 16.33it/s]\u001b[A\n",
            "Eval:   6%|▌         | 162/2805 [00:09<02:41, 16.36it/s]\u001b[A\n",
            "Eval:   6%|▌         | 164/2805 [00:09<02:41, 16.37it/s]\u001b[A\n",
            "Eval:   6%|▌         | 166/2805 [00:10<02:40, 16.44it/s]\u001b[A\n",
            "Eval:   6%|▌         | 168/2805 [00:10<02:39, 16.54it/s]\u001b[A\n",
            "Eval:   6%|▌         | 170/2805 [00:10<02:39, 16.57it/s]\u001b[A\n",
            "Eval:   6%|▌         | 172/2805 [00:10<02:39, 16.55it/s]\u001b[A\n",
            "Eval:   6%|▌         | 174/2805 [00:10<02:38, 16.55it/s]\u001b[A\n",
            "Eval:   6%|▋         | 176/2805 [00:10<02:39, 16.51it/s]\u001b[A\n",
            "Eval:   6%|▋         | 178/2805 [00:10<02:39, 16.47it/s]\u001b[A\n",
            "Eval:   6%|▋         | 180/2805 [00:10<02:39, 16.41it/s]\u001b[A\n",
            "Eval:   6%|▋         | 182/2805 [00:11<02:40, 16.38it/s]\u001b[A\n",
            "Eval:   7%|▋         | 184/2805 [00:11<02:39, 16.48it/s]\u001b[A\n",
            "Eval:   7%|▋         | 186/2805 [00:11<02:39, 16.44it/s]\u001b[A\n",
            "Eval:   7%|▋         | 188/2805 [00:11<02:39, 16.38it/s]\u001b[A\n",
            "Eval:   7%|▋         | 190/2805 [00:11<02:39, 16.39it/s]\u001b[A\n",
            "Eval:   7%|▋         | 192/2805 [00:11<02:39, 16.42it/s]\u001b[A\n",
            "Eval:   7%|▋         | 194/2805 [00:11<02:39, 16.38it/s]\u001b[A\n",
            "Eval:   7%|▋         | 196/2805 [00:11<02:39, 16.37it/s]\u001b[A\n",
            "Eval:   7%|▋         | 198/2805 [00:12<02:39, 16.35it/s]\u001b[A\n",
            "Eval:   7%|▋         | 200/2805 [00:12<02:38, 16.40it/s]\u001b[A\n",
            "Eval:   7%|▋         | 202/2805 [00:12<02:38, 16.42it/s]\u001b[A\n",
            "Eval:   7%|▋         | 204/2805 [00:12<02:38, 16.46it/s]\u001b[A\n",
            "Eval:   7%|▋         | 206/2805 [00:12<02:37, 16.48it/s]\u001b[A\n",
            "Eval:   7%|▋         | 208/2805 [00:12<02:37, 16.52it/s]\u001b[A\n",
            "Eval:   7%|▋         | 210/2805 [00:12<02:37, 16.49it/s]\u001b[A\n",
            "Eval:   8%|▊         | 212/2805 [00:12<02:38, 16.38it/s]\u001b[A\n",
            "Eval:   8%|▊         | 214/2805 [00:13<02:39, 16.21it/s]\u001b[A\n",
            "Eval:   8%|▊         | 216/2805 [00:13<02:41, 16.07it/s]\u001b[A\n",
            "Eval:   8%|▊         | 218/2805 [00:13<02:41, 16.01it/s]\u001b[A\n",
            "Eval:   8%|▊         | 220/2805 [00:13<02:41, 15.99it/s]\u001b[A\n",
            "Eval:   8%|▊         | 222/2805 [00:13<02:40, 16.10it/s]\u001b[A\n",
            "Eval:   8%|▊         | 224/2805 [00:13<02:38, 16.25it/s]\u001b[A\n",
            "Eval:   8%|▊         | 226/2805 [00:13<02:39, 16.22it/s]\u001b[A\n",
            "Eval:   8%|▊         | 228/2805 [00:13<02:38, 16.23it/s]\u001b[A\n",
            "Eval:   8%|▊         | 230/2805 [00:14<02:38, 16.22it/s]\u001b[A\n",
            "Eval:   8%|▊         | 232/2805 [00:14<02:38, 16.26it/s]\u001b[A\n",
            "Eval:   8%|▊         | 234/2805 [00:14<02:38, 16.26it/s]\u001b[A\n",
            "Eval:   8%|▊         | 236/2805 [00:14<02:37, 16.36it/s]\u001b[A\n",
            "Eval:   8%|▊         | 238/2805 [00:14<02:36, 16.35it/s]\u001b[A\n",
            "Eval:   9%|▊         | 240/2805 [00:14<02:36, 16.43it/s]\u001b[A\n",
            "Eval:   9%|▊         | 242/2805 [00:14<02:36, 16.42it/s]\u001b[A\n",
            "Eval:   9%|▊         | 244/2805 [00:14<02:36, 16.39it/s]\u001b[A\n",
            "Eval:   9%|▉         | 246/2805 [00:14<02:35, 16.41it/s]\u001b[A\n",
            "Eval:   9%|▉         | 248/2805 [00:15<02:37, 16.28it/s]\u001b[A\n",
            "Eval:   9%|▉         | 250/2805 [00:15<02:35, 16.38it/s]\u001b[A\n",
            "Eval:   9%|▉         | 252/2805 [00:15<02:35, 16.37it/s]\u001b[A\n",
            "Eval:   9%|▉         | 254/2805 [00:15<02:34, 16.47it/s]\u001b[A\n",
            "Eval:   9%|▉         | 256/2805 [00:15<02:35, 16.42it/s]\u001b[A\n",
            "Eval:   9%|▉         | 258/2805 [00:15<02:35, 16.43it/s]\u001b[A\n",
            "Eval:   9%|▉         | 260/2805 [00:15<02:35, 16.39it/s]\u001b[A\n",
            "Eval:   9%|▉         | 262/2805 [00:15<02:34, 16.42it/s]\u001b[A\n",
            "Eval:   9%|▉         | 264/2805 [00:16<02:35, 16.35it/s]\u001b[A\n",
            "Eval:   9%|▉         | 266/2805 [00:16<02:35, 16.30it/s]\u001b[A\n",
            "Eval:  10%|▉         | 268/2805 [00:16<02:35, 16.30it/s]\u001b[A\n",
            "Eval:  10%|▉         | 270/2805 [00:16<02:34, 16.45it/s]\u001b[A\n",
            "Eval:  10%|▉         | 272/2805 [00:16<02:33, 16.45it/s]\u001b[A\n",
            "Eval:  10%|▉         | 274/2805 [00:16<02:33, 16.45it/s]\u001b[A\n",
            "Eval:  10%|▉         | 276/2805 [00:16<02:33, 16.50it/s]\u001b[A\n",
            "Eval:  10%|▉         | 278/2805 [00:16<02:33, 16.46it/s]\u001b[A\n",
            "Eval:  10%|▉         | 280/2805 [00:17<02:35, 16.24it/s]\u001b[A\n",
            "Eval:  10%|█         | 282/2805 [00:17<02:36, 16.08it/s]\u001b[A\n",
            "Eval:  10%|█         | 284/2805 [00:17<02:36, 16.06it/s]\u001b[A\n",
            "Eval:  10%|█         | 286/2805 [00:17<02:36, 16.14it/s]\u001b[A\n",
            "Eval:  10%|█         | 288/2805 [00:17<02:36, 16.08it/s]\u001b[A\n",
            "Eval:  10%|█         | 290/2805 [00:17<02:36, 16.12it/s]\u001b[A\n",
            "Eval:  10%|█         | 292/2805 [00:17<02:35, 16.20it/s]\u001b[A\n",
            "Eval:  10%|█         | 294/2805 [00:17<02:34, 16.22it/s]\u001b[A\n",
            "Eval:  11%|█         | 296/2805 [00:18<02:34, 16.29it/s]\u001b[A\n",
            "Eval:  11%|█         | 298/2805 [00:18<02:34, 16.27it/s]\u001b[A\n",
            "Eval:  11%|█         | 300/2805 [00:18<02:34, 16.21it/s]\u001b[A\n",
            "Eval:  11%|█         | 302/2805 [00:18<02:33, 16.29it/s]\u001b[A\n",
            "Eval:  11%|█         | 304/2805 [00:18<02:33, 16.31it/s]\u001b[A\n",
            "Eval:  11%|█         | 306/2805 [00:18<02:33, 16.32it/s]\u001b[A\n",
            "Eval:  11%|█         | 308/2805 [00:18<02:34, 16.12it/s]\u001b[A\n",
            "Eval:  11%|█         | 310/2805 [00:18<02:35, 16.01it/s]\u001b[A\n",
            "Eval:  11%|█         | 312/2805 [00:19<02:35, 16.00it/s]\u001b[A\n",
            "Eval:  11%|█         | 314/2805 [00:19<02:34, 16.07it/s]\u001b[A\n",
            "Eval:  11%|█▏        | 316/2805 [00:19<02:34, 16.10it/s]\u001b[A\n",
            "Eval:  11%|█▏        | 318/2805 [00:19<02:33, 16.24it/s]\u001b[A\n",
            "Eval:  11%|█▏        | 320/2805 [00:19<02:32, 16.29it/s]\u001b[A\n",
            "Eval:  11%|█▏        | 322/2805 [00:19<02:32, 16.25it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 324/2805 [00:19<02:31, 16.37it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 326/2805 [00:19<02:31, 16.39it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 328/2805 [00:20<02:31, 16.37it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 330/2805 [00:20<02:31, 16.36it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 332/2805 [00:20<02:31, 16.33it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 334/2805 [00:20<02:31, 16.30it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 336/2805 [00:20<02:31, 16.34it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 338/2805 [00:20<02:31, 16.26it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 340/2805 [00:20<02:31, 16.28it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 342/2805 [00:20<02:33, 16.04it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 344/2805 [00:21<02:34, 15.90it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 346/2805 [00:21<02:34, 15.96it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 348/2805 [00:21<02:33, 16.04it/s]\u001b[A\n",
            "Eval:  12%|█▏        | 350/2805 [00:21<02:31, 16.18it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 352/2805 [00:21<02:30, 16.30it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 354/2805 [00:21<02:30, 16.33it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 356/2805 [00:21<02:30, 16.29it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 358/2805 [00:21<02:30, 16.31it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 360/2805 [00:21<02:29, 16.31it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 362/2805 [00:22<02:29, 16.31it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 364/2805 [00:22<02:29, 16.34it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 366/2805 [00:22<02:29, 16.35it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 368/2805 [00:22<02:28, 16.37it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 370/2805 [00:22<02:28, 16.37it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 372/2805 [00:22<02:28, 16.43it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 374/2805 [00:22<02:28, 16.33it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 376/2805 [00:22<02:28, 16.36it/s]\u001b[A\n",
            "Eval:  13%|█▎        | 378/2805 [00:23<02:28, 16.31it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 380/2805 [00:23<02:29, 16.24it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 382/2805 [00:23<02:31, 16.01it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 384/2805 [00:23<02:31, 15.97it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 386/2805 [00:23<02:30, 16.02it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 388/2805 [00:23<02:30, 16.02it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 390/2805 [00:23<02:29, 16.11it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 392/2805 [00:23<02:28, 16.21it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 394/2805 [00:24<02:28, 16.28it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 396/2805 [00:24<02:29, 16.16it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 398/2805 [00:24<02:29, 16.11it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 400/2805 [00:24<02:29, 16.08it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 402/2805 [00:24<02:29, 16.02it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 404/2805 [00:24<02:29, 16.10it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 406/2805 [00:24<02:28, 16.13it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 408/2805 [00:24<02:27, 16.20it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 410/2805 [00:25<02:27, 16.27it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 412/2805 [00:25<02:28, 16.06it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 414/2805 [00:25<02:29, 15.95it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 416/2805 [00:25<02:30, 15.89it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 418/2805 [00:25<02:31, 15.72it/s]\u001b[A\n",
            "Eval:  15%|█▍        | 420/2805 [00:25<02:33, 15.55it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 422/2805 [00:25<02:31, 15.75it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 424/2805 [00:25<02:30, 15.82it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 426/2805 [00:26<02:28, 15.99it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 428/2805 [00:26<02:27, 16.16it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 430/2805 [00:26<02:27, 16.14it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 432/2805 [00:26<02:26, 16.21it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 434/2805 [00:26<02:25, 16.25it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 436/2805 [00:26<02:25, 16.33it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 438/2805 [00:26<02:25, 16.25it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 440/2805 [00:26<02:24, 16.36it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 442/2805 [00:27<02:23, 16.44it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 444/2805 [00:27<02:23, 16.43it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 446/2805 [00:27<02:24, 16.33it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 448/2805 [00:27<02:24, 16.33it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 450/2805 [00:27<02:24, 16.34it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 452/2805 [00:27<02:23, 16.34it/s]\u001b[A\n",
            "Eval:  16%|█▌        | 454/2805 [00:27<02:25, 16.16it/s]\u001b[A\n",
            "Eval:  16%|█▋        | 456/2805 [00:27<02:26, 16.01it/s]\u001b[A\n",
            "Eval:  16%|█▋        | 458/2805 [00:28<02:26, 15.97it/s]\u001b[A\n",
            "Eval:  16%|█▋        | 460/2805 [00:28<02:28, 15.84it/s]\u001b[A\n",
            "Eval:  16%|█▋        | 462/2805 [00:28<02:27, 15.88it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 464/2805 [00:28<02:28, 15.78it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 466/2805 [00:28<02:27, 15.89it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 468/2805 [00:28<02:26, 15.93it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 470/2805 [00:28<02:26, 15.99it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 472/2805 [00:28<02:26, 15.97it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 474/2805 [00:29<02:26, 15.96it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 476/2805 [00:29<02:25, 16.02it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 478/2805 [00:29<02:25, 16.04it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 480/2805 [00:29<02:24, 16.11it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 482/2805 [00:29<02:23, 16.17it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 484/2805 [00:29<02:24, 16.11it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 486/2805 [00:29<02:23, 16.19it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 488/2805 [00:29<02:22, 16.27it/s]\u001b[A\n",
            "Eval:  17%|█▋        | 490/2805 [00:30<02:21, 16.31it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 492/2805 [00:30<02:21, 16.40it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 494/2805 [00:30<02:20, 16.47it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 496/2805 [00:30<02:20, 16.48it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 498/2805 [00:30<02:21, 16.29it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 500/2805 [00:30<02:23, 16.04it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 502/2805 [00:30<02:23, 16.05it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 504/2805 [00:30<02:23, 15.98it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 506/2805 [00:31<02:24, 15.89it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 508/2805 [00:31<02:23, 16.05it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 510/2805 [00:31<02:21, 16.19it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 512/2805 [00:31<02:21, 16.25it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 514/2805 [00:31<02:20, 16.30it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 516/2805 [00:31<02:19, 16.36it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 518/2805 [00:31<02:19, 16.41it/s]\u001b[A\n",
            "Eval:  19%|█▊        | 520/2805 [00:31<02:19, 16.35it/s]\u001b[A\n",
            "Eval:  19%|█▊        | 522/2805 [00:32<02:19, 16.32it/s]\u001b[A\n",
            "Eval:  19%|█▊        | 524/2805 [00:32<02:21, 16.07it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 526/2805 [00:32<02:23, 15.92it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 528/2805 [00:32<02:22, 15.96it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 530/2805 [00:32<02:20, 16.15it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 532/2805 [00:32<02:21, 16.07it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 534/2805 [00:32<02:20, 16.21it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 536/2805 [00:32<02:19, 16.27it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 538/2805 [00:33<02:20, 16.16it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 540/2805 [00:33<02:22, 15.91it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 542/2805 [00:33<02:21, 16.01it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 544/2805 [00:33<02:20, 16.10it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 546/2805 [00:33<02:19, 16.22it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 548/2805 [00:33<02:18, 16.24it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 550/2805 [00:33<02:18, 16.33it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 552/2805 [00:33<02:17, 16.41it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 554/2805 [00:33<02:17, 16.38it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 556/2805 [00:34<02:18, 16.26it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 558/2805 [00:34<02:18, 16.19it/s]\u001b[A\n",
            "Eval:  20%|█▉        | 560/2805 [00:34<02:19, 16.09it/s]\u001b[A\n",
            "Eval:  20%|██        | 562/2805 [00:34<02:20, 15.99it/s]\u001b[A\n",
            "Eval:  20%|██        | 564/2805 [00:34<02:18, 16.14it/s]\u001b[A\n",
            "Eval:  20%|██        | 566/2805 [00:34<02:19, 16.07it/s]\u001b[A\n",
            "Eval:  20%|██        | 568/2805 [00:34<02:19, 16.04it/s]\u001b[A\n",
            "Eval:  20%|██        | 570/2805 [00:35<02:19, 15.98it/s]\u001b[A\n",
            "Eval:  20%|██        | 572/2805 [00:35<02:20, 15.90it/s]\u001b[A\n",
            "Eval:  20%|██        | 574/2805 [00:35<02:21, 15.76it/s]\u001b[A\n",
            "Eval:  21%|██        | 576/2805 [00:35<02:21, 15.80it/s]\u001b[A\n",
            "Eval:  21%|██        | 578/2805 [00:35<02:21, 15.76it/s]\u001b[A\n",
            "Eval:  21%|██        | 580/2805 [00:35<02:21, 15.72it/s]\u001b[A\n",
            "Eval:  21%|██        | 582/2805 [00:35<02:21, 15.69it/s]\u001b[A\n",
            "Eval:  21%|██        | 584/2805 [00:35<02:21, 15.70it/s]\u001b[A\n",
            "Eval:  21%|██        | 586/2805 [00:36<02:21, 15.63it/s]\u001b[A\n",
            "Eval:  21%|██        | 588/2805 [00:36<02:20, 15.79it/s]\u001b[A\n",
            "Eval:  21%|██        | 590/2805 [00:36<02:19, 15.86it/s]\u001b[A\n",
            "Eval:  21%|██        | 592/2805 [00:36<02:19, 15.89it/s]\u001b[A\n",
            "Eval:  21%|██        | 594/2805 [00:36<02:17, 16.06it/s]\u001b[A\n",
            "Eval:  21%|██        | 596/2805 [00:36<02:16, 16.22it/s]\u001b[A\n",
            "Eval:  21%|██▏       | 598/2805 [00:36<02:15, 16.26it/s]\u001b[A\n",
            "Eval:  21%|██▏       | 600/2805 [00:36<02:15, 16.30it/s]\u001b[A\n",
            "Eval:  21%|██▏       | 602/2805 [00:37<02:14, 16.32it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 604/2805 [00:37<02:14, 16.37it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 606/2805 [00:37<02:14, 16.37it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 608/2805 [00:37<02:13, 16.40it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 610/2805 [00:37<02:13, 16.50it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 612/2805 [00:37<02:12, 16.51it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 614/2805 [00:37<02:12, 16.51it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 616/2805 [00:37<02:12, 16.51it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 618/2805 [00:37<02:12, 16.51it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 620/2805 [00:38<02:12, 16.44it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 622/2805 [00:38<02:13, 16.39it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 624/2805 [00:38<02:12, 16.43it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 626/2805 [00:38<02:13, 16.28it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 628/2805 [00:38<02:15, 16.10it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 630/2805 [00:38<02:14, 16.17it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 632/2805 [00:38<02:14, 16.20it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 634/2805 [00:38<02:15, 16.01it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 636/2805 [00:39<02:16, 15.93it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 638/2805 [00:39<02:14, 16.06it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 640/2805 [00:39<02:14, 16.14it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 642/2805 [00:39<02:13, 16.22it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 644/2805 [00:39<02:11, 16.39it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 646/2805 [00:39<02:11, 16.47it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 648/2805 [00:39<02:11, 16.41it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 650/2805 [00:39<02:11, 16.38it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 652/2805 [00:40<02:11, 16.42it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 654/2805 [00:40<02:10, 16.47it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 656/2805 [00:40<02:10, 16.49it/s]\u001b[A\n",
            "Eval:  23%|██▎       | 658/2805 [00:40<02:10, 16.50it/s]\u001b[A\n",
            "Eval:  24%|██▎       | 660/2805 [00:40<02:10, 16.48it/s]\u001b[A\n",
            "Eval:  24%|██▎       | 662/2805 [00:40<02:09, 16.50it/s]\u001b[A\n",
            "Eval:  24%|██▎       | 664/2805 [00:40<02:09, 16.48it/s]\u001b[A\n",
            "Eval:  24%|██▎       | 666/2805 [00:40<02:11, 16.25it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 668/2805 [00:41<02:10, 16.35it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 670/2805 [00:41<02:10, 16.38it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 672/2805 [00:41<02:09, 16.42it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 674/2805 [00:41<02:09, 16.40it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 676/2805 [00:41<02:09, 16.47it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 678/2805 [00:41<02:08, 16.58it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 680/2805 [00:41<02:08, 16.48it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 682/2805 [00:41<02:08, 16.49it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 684/2805 [00:42<02:08, 16.53it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 686/2805 [00:42<02:08, 16.48it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 688/2805 [00:42<02:08, 16.42it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 690/2805 [00:42<02:08, 16.46it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 692/2805 [00:42<02:08, 16.44it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 694/2805 [00:42<02:08, 16.45it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 696/2805 [00:42<02:08, 16.43it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 698/2805 [00:42<02:08, 16.44it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 700/2805 [00:42<02:07, 16.47it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 702/2805 [00:43<02:09, 16.27it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 704/2805 [00:43<02:08, 16.30it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 706/2805 [00:43<02:08, 16.40it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 708/2805 [00:43<02:07, 16.46it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 710/2805 [00:43<02:06, 16.53it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 712/2805 [00:43<02:07, 16.46it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 714/2805 [00:43<02:06, 16.51it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 716/2805 [00:43<02:06, 16.47it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 718/2805 [00:44<02:07, 16.43it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 720/2805 [00:44<02:08, 16.26it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 722/2805 [00:44<02:07, 16.40it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 724/2805 [00:44<02:06, 16.51it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 726/2805 [00:44<02:06, 16.48it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 728/2805 [00:44<02:06, 16.46it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 730/2805 [00:44<02:06, 16.47it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 732/2805 [00:44<02:07, 16.23it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 734/2805 [00:45<02:06, 16.36it/s]\u001b[A\n",
            "Eval:  26%|██▌       | 736/2805 [00:45<02:06, 16.36it/s]\u001b[A\n",
            "Eval:  26%|██▋       | 738/2805 [00:45<02:05, 16.48it/s]\u001b[A\n",
            "Eval:  26%|██▋       | 740/2805 [00:45<02:06, 16.38it/s]\u001b[A\n",
            "Eval:  26%|██▋       | 742/2805 [00:45<02:07, 16.21it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 744/2805 [00:45<02:08, 16.07it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 746/2805 [00:45<02:09, 15.95it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 748/2805 [00:45<02:07, 16.11it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 750/2805 [00:46<02:06, 16.19it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 752/2805 [00:46<02:06, 16.29it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 754/2805 [00:46<02:05, 16.35it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 756/2805 [00:46<02:05, 16.29it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 758/2805 [00:46<02:06, 16.18it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 760/2805 [00:46<02:05, 16.25it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 762/2805 [00:46<02:04, 16.37it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 764/2805 [00:46<02:03, 16.48it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 766/2805 [00:47<02:03, 16.55it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 768/2805 [00:47<02:03, 16.55it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 770/2805 [00:47<02:03, 16.53it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 772/2805 [00:47<02:03, 16.42it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 774/2805 [00:47<02:04, 16.37it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 776/2805 [00:47<02:03, 16.39it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 778/2805 [00:47<02:03, 16.39it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 780/2805 [00:47<02:03, 16.45it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 782/2805 [00:47<02:02, 16.49it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 784/2805 [00:48<02:02, 16.46it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 786/2805 [00:48<02:03, 16.38it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 788/2805 [00:48<02:02, 16.41it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 790/2805 [00:48<02:03, 16.37it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 792/2805 [00:48<02:02, 16.40it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 794/2805 [00:48<02:02, 16.45it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 796/2805 [00:48<02:01, 16.54it/s]\u001b[A\n",
            "Eval:  28%|██▊       | 798/2805 [00:48<02:01, 16.52it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 800/2805 [00:49<02:03, 16.29it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 802/2805 [00:49<02:03, 16.23it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 804/2805 [00:49<02:02, 16.30it/s]\u001b[A\n",
            "Eval:  29%|██▊       | 806/2805 [00:49<02:02, 16.33it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 808/2805 [00:49<02:01, 16.39it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 810/2805 [00:49<02:01, 16.41it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 812/2805 [00:49<02:00, 16.56it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 814/2805 [00:49<02:01, 16.36it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 816/2805 [00:50<02:02, 16.23it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 818/2805 [00:50<02:01, 16.33it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 820/2805 [00:50<02:03, 16.11it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 822/2805 [00:50<02:03, 16.01it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 824/2805 [00:50<02:02, 16.20it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 826/2805 [00:50<02:01, 16.32it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 828/2805 [00:50<02:01, 16.24it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 830/2805 [00:50<02:02, 16.16it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 832/2805 [00:51<02:01, 16.18it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 834/2805 [00:51<02:03, 15.99it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 836/2805 [00:51<02:02, 16.02it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 838/2805 [00:51<02:03, 15.97it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 840/2805 [00:51<02:02, 16.03it/s]\u001b[A\n",
            "Eval:  30%|███       | 842/2805 [00:51<02:01, 16.18it/s]\u001b[A\n",
            "Eval:  30%|███       | 844/2805 [00:51<02:00, 16.27it/s]\u001b[A\n",
            "Eval:  30%|███       | 846/2805 [00:51<01:59, 16.38it/s]\u001b[A\n",
            "Eval:  30%|███       | 848/2805 [00:52<02:00, 16.22it/s]\u001b[A\n",
            "Eval:  30%|███       | 850/2805 [00:52<02:02, 16.02it/s]\u001b[A\n",
            "Eval:  30%|███       | 852/2805 [00:52<02:01, 16.02it/s]\u001b[A\n",
            "Eval:  30%|███       | 854/2805 [00:52<02:01, 16.02it/s]\u001b[A\n",
            "Eval:  31%|███       | 856/2805 [00:52<02:00, 16.21it/s]\u001b[A\n",
            "Eval:  31%|███       | 858/2805 [00:52<01:59, 16.29it/s]\u001b[A\n",
            "Eval:  31%|███       | 860/2805 [00:52<01:59, 16.22it/s]\u001b[A\n",
            "Eval:  31%|███       | 862/2805 [00:52<01:59, 16.20it/s]\u001b[A\n",
            "Eval:  31%|███       | 864/2805 [00:53<01:58, 16.34it/s]\u001b[A\n",
            "Eval:  31%|███       | 866/2805 [00:53<01:57, 16.44it/s]\u001b[A\n",
            "Eval:  31%|███       | 868/2805 [00:53<01:58, 16.37it/s]\u001b[A\n",
            "Eval:  31%|███       | 870/2805 [00:53<01:57, 16.49it/s]\u001b[A\n",
            "Eval:  31%|███       | 872/2805 [00:53<01:57, 16.49it/s]\u001b[A\n",
            "Eval:  31%|███       | 874/2805 [00:53<01:57, 16.43it/s]\u001b[A\n",
            "Eval:  31%|███       | 876/2805 [00:53<01:57, 16.44it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 878/2805 [00:53<01:57, 16.38it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 880/2805 [00:54<01:57, 16.40it/s]\u001b[A\n",
            "Eval:  31%|███▏      | 882/2805 [00:54<01:57, 16.38it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 884/2805 [00:54<01:57, 16.40it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 886/2805 [00:54<01:57, 16.36it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 888/2805 [00:54<01:58, 16.23it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 890/2805 [00:54<01:57, 16.30it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 892/2805 [00:54<01:56, 16.37it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 894/2805 [00:54<01:58, 16.11it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 896/2805 [00:55<02:00, 15.79it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 898/2805 [00:55<01:58, 16.04it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 900/2805 [00:55<01:57, 16.24it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 902/2805 [00:55<01:56, 16.29it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 904/2805 [00:55<01:56, 16.26it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 906/2805 [00:55<01:55, 16.39it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 908/2805 [00:55<01:55, 16.39it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 910/2805 [00:55<01:55, 16.40it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 912/2805 [00:55<01:55, 16.43it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 914/2805 [00:56<01:55, 16.41it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 916/2805 [00:56<01:54, 16.44it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 918/2805 [00:56<01:54, 16.45it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 920/2805 [00:56<01:55, 16.39it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 922/2805 [00:56<01:54, 16.42it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 924/2805 [00:56<01:53, 16.50it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 926/2805 [00:56<01:54, 16.41it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 928/2805 [00:56<01:54, 16.37it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 930/2805 [00:57<01:53, 16.46it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 932/2805 [00:57<01:54, 16.35it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 934/2805 [00:57<01:55, 16.21it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 936/2805 [00:57<01:54, 16.31it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 938/2805 [00:57<01:53, 16.41it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 940/2805 [00:57<01:53, 16.44it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 942/2805 [00:57<01:53, 16.42it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 944/2805 [00:57<01:53, 16.38it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 946/2805 [00:58<01:53, 16.44it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 948/2805 [00:58<01:53, 16.38it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 950/2805 [00:58<01:52, 16.47it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 952/2805 [00:58<01:52, 16.47it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 954/2805 [00:58<01:52, 16.42it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 956/2805 [00:58<01:53, 16.33it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 958/2805 [00:58<01:52, 16.41it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 960/2805 [00:58<01:51, 16.50it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 962/2805 [00:59<01:51, 16.47it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 964/2805 [00:59<01:52, 16.41it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 966/2805 [00:59<01:51, 16.48it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 968/2805 [00:59<01:51, 16.45it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 970/2805 [00:59<01:51, 16.43it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 972/2805 [00:59<01:51, 16.39it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 974/2805 [00:59<01:51, 16.43it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 976/2805 [00:59<01:50, 16.53it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 978/2805 [00:59<01:50, 16.50it/s]\u001b[A\n",
            "Eval:  35%|███▍      | 980/2805 [01:00<01:50, 16.44it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 982/2805 [01:00<01:50, 16.44it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 984/2805 [01:00<01:51, 16.29it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 986/2805 [01:00<01:51, 16.38it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 988/2805 [01:00<01:49, 16.52it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 990/2805 [01:00<01:49, 16.54it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 992/2805 [01:00<01:50, 16.42it/s]\u001b[A\n",
            "Eval:  35%|███▌      | 994/2805 [01:00<01:49, 16.49it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 996/2805 [01:01<01:49, 16.48it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 998/2805 [01:01<01:50, 16.37it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1000/2805 [01:01<01:49, 16.42it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1002/2805 [01:01<01:49, 16.44it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1004/2805 [01:01<01:49, 16.50it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1006/2805 [01:01<01:49, 16.41it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1008/2805 [01:01<01:49, 16.39it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1010/2805 [01:01<01:48, 16.49it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1012/2805 [01:02<01:48, 16.53it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1014/2805 [01:02<01:48, 16.50it/s]\u001b[A\n",
            "Eval:  36%|███▌      | 1016/2805 [01:02<01:48, 16.50it/s]\u001b[A\n",
            "Eval:  36%|███▋      | 1018/2805 [01:02<01:48, 16.50it/s]\u001b[A\n",
            "Eval:  36%|███▋      | 1020/2805 [01:02<01:48, 16.43it/s]\u001b[A\n",
            "Eval:  36%|███▋      | 1022/2805 [01:02<01:49, 16.30it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1024/2805 [01:02<01:48, 16.38it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1026/2805 [01:02<01:48, 16.44it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1028/2805 [01:03<01:47, 16.51it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1030/2805 [01:03<01:47, 16.51it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1032/2805 [01:03<01:47, 16.48it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1034/2805 [01:03<01:48, 16.27it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1036/2805 [01:03<01:48, 16.28it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1038/2805 [01:03<01:48, 16.31it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1040/2805 [01:03<01:47, 16.39it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1042/2805 [01:03<01:46, 16.48it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1044/2805 [01:04<01:46, 16.61it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1046/2805 [01:04<01:46, 16.58it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1048/2805 [01:04<01:47, 16.35it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 1050/2805 [01:04<01:47, 16.37it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1052/2805 [01:04<01:46, 16.39it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1054/2805 [01:04<01:46, 16.43it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1056/2805 [01:04<01:46, 16.44it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1058/2805 [01:04<01:46, 16.34it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1060/2805 [01:04<01:45, 16.48it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1062/2805 [01:05<01:45, 16.49it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1064/2805 [01:05<01:45, 16.54it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1066/2805 [01:05<01:45, 16.55it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1068/2805 [01:05<01:45, 16.52it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1070/2805 [01:05<01:45, 16.48it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1072/2805 [01:05<01:46, 16.27it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1074/2805 [01:05<01:45, 16.42it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1076/2805 [01:05<01:45, 16.35it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 1078/2805 [01:06<01:46, 16.18it/s]\u001b[A\n",
            "Eval:  39%|███▊      | 1080/2805 [01:06<01:45, 16.39it/s]\u001b[A\n",
            "Eval:  39%|███▊      | 1082/2805 [01:06<01:44, 16.48it/s]\u001b[A\n",
            "Eval:  39%|███▊      | 1084/2805 [01:06<01:44, 16.53it/s]\u001b[A\n",
            "Eval:  39%|███▊      | 1086/2805 [01:06<01:44, 16.49it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1088/2805 [01:06<01:44, 16.45it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1090/2805 [01:06<01:44, 16.42it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1092/2805 [01:06<01:43, 16.47it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1094/2805 [01:07<01:43, 16.53it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1096/2805 [01:07<01:45, 16.27it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1098/2805 [01:07<01:43, 16.45it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1100/2805 [01:07<01:43, 16.51it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1102/2805 [01:07<01:42, 16.62it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1104/2805 [01:07<01:42, 16.57it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 1106/2805 [01:07<01:42, 16.51it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1108/2805 [01:07<01:42, 16.52it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1110/2805 [01:08<01:42, 16.49it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1112/2805 [01:08<01:42, 16.46it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1114/2805 [01:08<01:42, 16.46it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1116/2805 [01:08<01:42, 16.40it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1118/2805 [01:08<01:42, 16.47it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 1120/2805 [01:08<01:42, 16.50it/s]\u001b[A\n",
            "Eval:  40%|████      | 1122/2805 [01:08<01:42, 16.46it/s]\u001b[A\n",
            "Eval:  40%|████      | 1124/2805 [01:08<01:42, 16.47it/s]\u001b[A\n",
            "Eval:  40%|████      | 1126/2805 [01:08<01:41, 16.46it/s]\u001b[A\n",
            "Eval:  40%|████      | 1128/2805 [01:09<01:41, 16.44it/s]\u001b[A\n",
            "Eval:  40%|████      | 1130/2805 [01:09<01:42, 16.41it/s]\u001b[A\n",
            "Eval:  40%|████      | 1132/2805 [01:09<01:42, 16.27it/s]\u001b[A\n",
            "Eval:  40%|████      | 1134/2805 [01:09<01:42, 16.34it/s]\u001b[A\n",
            "Eval:  40%|████      | 1136/2805 [01:09<01:41, 16.44it/s]\u001b[A\n",
            "Eval:  41%|████      | 1138/2805 [01:09<01:40, 16.52it/s]\u001b[A\n",
            "Eval:  41%|████      | 1140/2805 [01:09<01:40, 16.59it/s]\u001b[A\n",
            "Eval:  41%|████      | 1142/2805 [01:09<01:39, 16.63it/s]\u001b[A\n",
            "Eval:  41%|████      | 1144/2805 [01:10<01:40, 16.50it/s]\u001b[A\n",
            "Eval:  41%|████      | 1146/2805 [01:10<01:42, 16.23it/s]\u001b[A\n",
            "Eval:  41%|████      | 1148/2805 [01:10<01:42, 16.16it/s]\u001b[A\n",
            "Eval:  41%|████      | 1150/2805 [01:10<01:42, 16.12it/s]\u001b[A\n",
            "Eval:  41%|████      | 1152/2805 [01:10<01:40, 16.38it/s]\u001b[A\n",
            "Eval:  41%|████      | 1154/2805 [01:10<01:39, 16.54it/s]\u001b[A\n",
            "Eval:  41%|████      | 1156/2805 [01:10<01:39, 16.63it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 1158/2805 [01:10<01:39, 16.61it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 1160/2805 [01:11<01:39, 16.56it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 1162/2805 [01:11<01:39, 16.54it/s]\u001b[A\n",
            "Eval:  41%|████▏     | 1164/2805 [01:11<01:40, 16.36it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1166/2805 [01:11<01:41, 16.21it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1168/2805 [01:11<01:40, 16.28it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1170/2805 [01:11<01:40, 16.35it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1172/2805 [01:11<01:39, 16.35it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1174/2805 [01:11<01:40, 16.21it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1176/2805 [01:12<01:39, 16.41it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1178/2805 [01:12<01:38, 16.46it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1180/2805 [01:12<01:38, 16.53it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1182/2805 [01:12<01:38, 16.54it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1184/2805 [01:12<01:37, 16.63it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1186/2805 [01:12<01:37, 16.67it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1188/2805 [01:12<01:36, 16.68it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1190/2805 [01:12<01:37, 16.65it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 1192/2805 [01:13<01:37, 16.55it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1194/2805 [01:13<01:37, 16.54it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1196/2805 [01:13<01:37, 16.57it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1198/2805 [01:13<01:37, 16.46it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1200/2805 [01:13<01:38, 16.26it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1202/2805 [01:13<01:39, 16.11it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1204/2805 [01:13<01:38, 16.33it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1206/2805 [01:13<01:37, 16.44it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1208/2805 [01:13<01:36, 16.52it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1210/2805 [01:14<01:36, 16.57it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1212/2805 [01:14<01:36, 16.56it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1214/2805 [01:14<01:36, 16.52it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1216/2805 [01:14<01:37, 16.28it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1218/2805 [01:14<01:38, 16.10it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 1220/2805 [01:14<01:39, 16.01it/s]\u001b[A\n",
            "Eval:  44%|████▎     | 1222/2805 [01:14<01:38, 16.11it/s]\u001b[A\n",
            "Eval:  44%|████▎     | 1224/2805 [01:14<01:38, 16.07it/s]\u001b[A\n",
            "Eval:  44%|████▎     | 1226/2805 [01:15<01:38, 15.97it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1228/2805 [01:15<01:37, 16.18it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1230/2805 [01:15<01:37, 16.23it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1232/2805 [01:15<01:36, 16.32it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1234/2805 [01:15<01:36, 16.35it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1236/2805 [01:15<01:34, 16.52it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1238/2805 [01:15<01:35, 16.49it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1240/2805 [01:15<01:35, 16.45it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1242/2805 [01:16<01:34, 16.48it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1244/2805 [01:16<01:34, 16.46it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1246/2805 [01:16<01:34, 16.44it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 1248/2805 [01:16<01:34, 16.39it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1250/2805 [01:16<01:34, 16.47it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1252/2805 [01:16<01:34, 16.43it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1254/2805 [01:16<01:35, 16.28it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1256/2805 [01:16<01:35, 16.29it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1258/2805 [01:17<01:34, 16.35it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1260/2805 [01:17<01:34, 16.32it/s]\u001b[A\n",
            "Eval:  45%|████▍     | 1262/2805 [01:17<01:35, 16.10it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1264/2805 [01:17<01:35, 16.16it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1266/2805 [01:17<01:35, 16.09it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1268/2805 [01:17<01:35, 16.12it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1270/2805 [01:17<01:34, 16.21it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1272/2805 [01:17<01:34, 16.15it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1274/2805 [01:18<01:35, 16.11it/s]\u001b[A\n",
            "Eval:  45%|████▌     | 1276/2805 [01:18<01:34, 16.11it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1278/2805 [01:18<01:34, 16.19it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1280/2805 [01:18<01:34, 16.07it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1282/2805 [01:18<01:33, 16.29it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1284/2805 [01:18<01:32, 16.49it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1286/2805 [01:18<01:31, 16.58it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1288/2805 [01:18<01:32, 16.46it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1290/2805 [01:19<01:32, 16.35it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1292/2805 [01:19<01:33, 16.18it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1294/2805 [01:19<01:32, 16.38it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 1296/2805 [01:19<01:31, 16.48it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 1298/2805 [01:19<01:32, 16.31it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 1300/2805 [01:19<01:31, 16.45it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 1302/2805 [01:19<01:30, 16.52it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 1304/2805 [01:19<01:30, 16.58it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1306/2805 [01:19<01:30, 16.57it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1308/2805 [01:20<01:30, 16.53it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1310/2805 [01:20<01:30, 16.51it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1312/2805 [01:20<01:30, 16.53it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1314/2805 [01:20<01:30, 16.42it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1316/2805 [01:20<01:30, 16.44it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1318/2805 [01:20<01:29, 16.54it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1320/2805 [01:20<01:29, 16.52it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1322/2805 [01:20<01:30, 16.46it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1324/2805 [01:21<01:29, 16.50it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1326/2805 [01:21<01:29, 16.45it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1328/2805 [01:21<01:30, 16.38it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1330/2805 [01:21<01:30, 16.38it/s]\u001b[A\n",
            "Eval:  47%|████▋     | 1332/2805 [01:21<01:29, 16.41it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1334/2805 [01:21<01:29, 16.49it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1336/2805 [01:21<01:29, 16.49it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1338/2805 [01:21<01:28, 16.52it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1340/2805 [01:22<01:28, 16.49it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1342/2805 [01:22<01:28, 16.46it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1344/2805 [01:22<01:29, 16.35it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1346/2805 [01:22<01:30, 16.16it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1348/2805 [01:22<01:29, 16.34it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1350/2805 [01:22<01:29, 16.27it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1352/2805 [01:22<01:28, 16.35it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1354/2805 [01:22<01:29, 16.29it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1356/2805 [01:23<01:29, 16.19it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1358/2805 [01:23<01:28, 16.37it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 1360/2805 [01:23<01:28, 16.27it/s]\u001b[A\n",
            "Eval:  49%|████▊     | 1362/2805 [01:23<01:28, 16.31it/s]\u001b[A\n",
            "Eval:  49%|████▊     | 1364/2805 [01:23<01:28, 16.20it/s]\u001b[A\n",
            "Eval:  49%|████▊     | 1366/2805 [01:23<01:29, 16.08it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1368/2805 [01:23<01:28, 16.19it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1370/2805 [01:23<01:28, 16.23it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1372/2805 [01:24<01:27, 16.29it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1374/2805 [01:24<01:28, 16.19it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1376/2805 [01:24<01:27, 16.29it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1378/2805 [01:24<01:27, 16.25it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1380/2805 [01:24<01:27, 16.33it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1382/2805 [01:24<01:26, 16.44it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1384/2805 [01:24<01:26, 16.45it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1386/2805 [01:24<01:26, 16.40it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 1388/2805 [01:25<01:26, 16.39it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1390/2805 [01:25<01:27, 16.20it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1392/2805 [01:25<01:27, 16.23it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1394/2805 [01:25<01:26, 16.33it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1396/2805 [01:25<01:25, 16.39it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1398/2805 [01:25<01:26, 16.29it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1400/2805 [01:25<01:25, 16.40it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 1402/2805 [01:25<01:25, 16.50it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1404/2805 [01:25<01:24, 16.56it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1406/2805 [01:26<01:24, 16.52it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1408/2805 [01:26<01:25, 16.39it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1410/2805 [01:26<01:24, 16.43it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1412/2805 [01:26<01:24, 16.45it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1414/2805 [01:26<01:24, 16.41it/s]\u001b[A\n",
            "Eval:  50%|█████     | 1416/2805 [01:26<01:24, 16.50it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1418/2805 [01:26<01:23, 16.55it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1420/2805 [01:26<01:23, 16.52it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1422/2805 [01:27<01:23, 16.52it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1424/2805 [01:27<01:24, 16.36it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1426/2805 [01:27<01:23, 16.43it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1428/2805 [01:27<01:25, 16.18it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1430/2805 [01:27<01:24, 16.29it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1432/2805 [01:27<01:24, 16.34it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1434/2805 [01:27<01:24, 16.28it/s]\u001b[A\n",
            "Eval:  51%|█████     | 1436/2805 [01:27<01:23, 16.45it/s]\u001b[A\n",
            "Eval:  51%|█████▏    | 1438/2805 [01:28<01:23, 16.46it/s]\u001b[A\n",
            "Eval:  51%|█████▏    | 1440/2805 [01:28<01:23, 16.42it/s]\u001b[A\n",
            "Eval:  51%|█████▏    | 1442/2805 [01:28<01:23, 16.37it/s]\u001b[A\n",
            "Eval:  51%|█████▏    | 1444/2805 [01:28<01:22, 16.42it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1446/2805 [01:28<01:22, 16.49it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1448/2805 [01:28<01:23, 16.35it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1450/2805 [01:28<01:23, 16.25it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1452/2805 [01:28<01:23, 16.18it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1454/2805 [01:29<01:24, 15.95it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1456/2805 [01:29<01:25, 15.87it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1458/2805 [01:29<01:24, 15.96it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1460/2805 [01:29<01:23, 16.09it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1462/2805 [01:29<01:22, 16.28it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1464/2805 [01:29<01:21, 16.39it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1466/2805 [01:29<01:22, 16.27it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1468/2805 [01:29<01:22, 16.13it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1470/2805 [01:30<01:22, 16.18it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 1472/2805 [01:30<01:22, 16.23it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1474/2805 [01:30<01:21, 16.37it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1476/2805 [01:30<01:20, 16.43it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1478/2805 [01:30<01:20, 16.53it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1480/2805 [01:30<01:20, 16.50it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1482/2805 [01:30<01:20, 16.53it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1484/2805 [01:30<01:19, 16.57it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1486/2805 [01:30<01:19, 16.54it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1488/2805 [01:31<01:20, 16.35it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1490/2805 [01:31<01:20, 16.24it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1492/2805 [01:31<01:20, 16.25it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1494/2805 [01:31<01:20, 16.37it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1496/2805 [01:31<01:20, 16.29it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1498/2805 [01:31<01:19, 16.49it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 1500/2805 [01:31<01:18, 16.53it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 1502/2805 [01:31<01:19, 16.39it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 1504/2805 [01:32<01:19, 16.45it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 1506/2805 [01:32<01:18, 16.45it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1508/2805 [01:32<01:18, 16.52it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1510/2805 [01:32<01:18, 16.54it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1512/2805 [01:32<01:18, 16.54it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1514/2805 [01:32<01:18, 16.49it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1516/2805 [01:32<01:17, 16.53it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1518/2805 [01:32<01:17, 16.56it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1520/2805 [01:33<01:18, 16.44it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1522/2805 [01:33<01:18, 16.38it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1524/2805 [01:33<01:17, 16.43it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1526/2805 [01:33<01:18, 16.20it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 1528/2805 [01:33<01:19, 16.11it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1530/2805 [01:33<01:19, 16.08it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1532/2805 [01:33<01:18, 16.29it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1534/2805 [01:33<01:19, 16.00it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1536/2805 [01:34<01:18, 16.15it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1538/2805 [01:34<01:18, 16.07it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1540/2805 [01:34<01:18, 16.05it/s]\u001b[A\n",
            "Eval:  55%|█████▍    | 1542/2805 [01:34<01:18, 15.99it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1544/2805 [01:34<01:18, 16.04it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1546/2805 [01:34<01:17, 16.30it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1548/2805 [01:34<01:16, 16.40it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1550/2805 [01:34<01:16, 16.42it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1552/2805 [01:35<01:15, 16.54it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1554/2805 [01:35<01:15, 16.61it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 1556/2805 [01:35<01:16, 16.42it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1558/2805 [01:35<01:16, 16.39it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1560/2805 [01:35<01:15, 16.43it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1562/2805 [01:35<01:16, 16.32it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1564/2805 [01:35<01:18, 15.90it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1566/2805 [01:35<01:17, 15.96it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1568/2805 [01:36<01:17, 15.95it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1570/2805 [01:36<01:16, 16.24it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1572/2805 [01:36<01:16, 16.17it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1574/2805 [01:36<01:17, 15.94it/s]\u001b[A\n",
            "Eval:  56%|█████▌    | 1576/2805 [01:36<01:17, 15.92it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 1578/2805 [01:36<01:16, 15.99it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 1580/2805 [01:36<01:15, 16.14it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 1582/2805 [01:36<01:15, 16.25it/s]\u001b[A\n",
            "Eval:  56%|█████▋    | 1584/2805 [01:37<01:15, 16.27it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1586/2805 [01:37<01:14, 16.35it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1588/2805 [01:37<01:14, 16.33it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1590/2805 [01:37<01:14, 16.40it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1592/2805 [01:37<01:13, 16.48it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1594/2805 [01:37<01:13, 16.40it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1596/2805 [01:37<01:13, 16.51it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1598/2805 [01:37<01:13, 16.48it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1600/2805 [01:37<01:13, 16.45it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1602/2805 [01:38<01:13, 16.42it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1604/2805 [01:38<01:14, 16.14it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1606/2805 [01:38<01:13, 16.31it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1608/2805 [01:38<01:13, 16.28it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1610/2805 [01:38<01:14, 16.15it/s]\u001b[A\n",
            "Eval:  57%|█████▋    | 1612/2805 [01:38<01:14, 16.00it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1614/2805 [01:38<01:14, 15.94it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1616/2805 [01:38<01:15, 15.73it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1618/2805 [01:39<01:15, 15.68it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1620/2805 [01:39<01:14, 15.87it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1622/2805 [01:39<01:13, 16.06it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1624/2805 [01:39<01:13, 16.14it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1626/2805 [01:39<01:12, 16.24it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1628/2805 [01:39<01:12, 16.31it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1630/2805 [01:39<01:12, 16.19it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1632/2805 [01:39<01:12, 16.10it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1634/2805 [01:40<01:13, 15.92it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1636/2805 [01:40<01:13, 15.82it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1638/2805 [01:40<01:13, 15.91it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 1640/2805 [01:40<01:13, 15.84it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 1642/2805 [01:40<01:12, 16.09it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 1644/2805 [01:40<01:11, 16.29it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 1646/2805 [01:40<01:10, 16.39it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1648/2805 [01:40<01:10, 16.43it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1650/2805 [01:41<01:10, 16.45it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1652/2805 [01:41<01:10, 16.40it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1654/2805 [01:41<01:10, 16.42it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1656/2805 [01:41<01:11, 16.16it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1658/2805 [01:41<01:10, 16.32it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1660/2805 [01:41<01:10, 16.23it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1662/2805 [01:41<01:09, 16.46it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1664/2805 [01:41<01:08, 16.54it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1666/2805 [01:42<01:08, 16.54it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 1668/2805 [01:42<01:08, 16.49it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1670/2805 [01:42<01:09, 16.38it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1672/2805 [01:42<01:09, 16.23it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1674/2805 [01:42<01:10, 15.94it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1676/2805 [01:42<01:10, 16.07it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1678/2805 [01:42<01:09, 16.20it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1680/2805 [01:42<01:09, 16.26it/s]\u001b[A\n",
            "Eval:  60%|█████▉    | 1682/2805 [01:43<01:08, 16.32it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1684/2805 [01:43<01:08, 16.33it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1686/2805 [01:43<01:09, 16.15it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1688/2805 [01:43<01:09, 16.12it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1690/2805 [01:43<01:08, 16.25it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1692/2805 [01:43<01:08, 16.22it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1694/2805 [01:43<01:07, 16.39it/s]\u001b[A\n",
            "Eval:  60%|██████    | 1696/2805 [01:43<01:07, 16.47it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1698/2805 [01:44<01:06, 16.56it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1700/2805 [01:44<01:06, 16.56it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1702/2805 [01:44<01:06, 16.53it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1704/2805 [01:44<01:07, 16.42it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1706/2805 [01:44<01:06, 16.47it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1708/2805 [01:44<01:06, 16.50it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1710/2805 [01:44<01:06, 16.52it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1712/2805 [01:44<01:06, 16.55it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1714/2805 [01:45<01:06, 16.29it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1716/2805 [01:45<01:06, 16.40it/s]\u001b[A\n",
            "Eval:  61%|██████    | 1718/2805 [01:45<01:06, 16.41it/s]\u001b[A\n",
            "Eval:  61%|██████▏   | 1720/2805 [01:45<01:06, 16.26it/s]\u001b[A\n",
            "Eval:  61%|██████▏   | 1722/2805 [01:45<01:05, 16.42it/s]\u001b[A\n",
            "Eval:  61%|██████▏   | 1724/2805 [01:45<01:05, 16.50it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1726/2805 [01:45<01:05, 16.51it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1728/2805 [01:45<01:05, 16.45it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1730/2805 [01:45<01:05, 16.41it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1732/2805 [01:46<01:05, 16.50it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1734/2805 [01:46<01:05, 16.45it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1736/2805 [01:46<01:05, 16.40it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1738/2805 [01:46<01:04, 16.48it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1740/2805 [01:46<01:05, 16.19it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1742/2805 [01:46<01:05, 16.31it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1744/2805 [01:46<01:05, 16.10it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1746/2805 [01:46<01:05, 16.18it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1748/2805 [01:47<01:05, 16.19it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1750/2805 [01:47<01:05, 16.15it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 1752/2805 [01:47<01:05, 16.05it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1754/2805 [01:47<01:04, 16.22it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1756/2805 [01:47<01:04, 16.30it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1758/2805 [01:47<01:04, 16.34it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1760/2805 [01:47<01:03, 16.38it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1762/2805 [01:47<01:03, 16.43it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1764/2805 [01:48<01:03, 16.50it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1766/2805 [01:48<01:03, 16.37it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1768/2805 [01:48<01:03, 16.34it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1770/2805 [01:48<01:03, 16.40it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1772/2805 [01:48<01:03, 16.39it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1774/2805 [01:48<01:04, 16.09it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1776/2805 [01:48<01:05, 15.79it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1778/2805 [01:48<01:04, 16.02it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 1780/2805 [01:49<01:03, 16.19it/s]\u001b[A\n",
            "Eval:  64%|██████▎   | 1782/2805 [01:49<01:02, 16.34it/s]\u001b[A\n",
            "Eval:  64%|██████▎   | 1784/2805 [01:49<01:02, 16.33it/s]\u001b[A\n",
            "Eval:  64%|██████▎   | 1786/2805 [01:49<01:03, 16.17it/s]\u001b[A\n",
            "Eval:  64%|██████▎   | 1788/2805 [01:49<01:03, 15.98it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1790/2805 [01:49<01:03, 15.91it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1792/2805 [01:49<01:03, 15.86it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1794/2805 [01:49<01:03, 16.05it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1796/2805 [01:50<01:02, 16.14it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1798/2805 [01:50<01:01, 16.27it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1800/2805 [01:50<01:01, 16.36it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1802/2805 [01:50<01:01, 16.28it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1804/2805 [01:50<01:01, 16.36it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1806/2805 [01:50<01:01, 16.35it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 1808/2805 [01:50<01:00, 16.40it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1810/2805 [01:50<01:01, 16.29it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1812/2805 [01:51<01:00, 16.33it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1814/2805 [01:51<01:01, 16.03it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1816/2805 [01:51<01:01, 16.09it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1818/2805 [01:51<01:01, 16.11it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1820/2805 [01:51<01:00, 16.15it/s]\u001b[A\n",
            "Eval:  65%|██████▍   | 1822/2805 [01:51<01:00, 16.21it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1824/2805 [01:51<01:00, 16.17it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1826/2805 [01:51<01:00, 16.32it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1828/2805 [01:52<01:00, 16.23it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1830/2805 [01:52<00:59, 16.34it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1832/2805 [01:52<00:59, 16.40it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1834/2805 [01:52<01:00, 16.12it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 1836/2805 [01:52<01:00, 16.02it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1838/2805 [01:52<01:00, 15.96it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1840/2805 [01:52<00:59, 16.09it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1842/2805 [01:52<00:59, 16.11it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1844/2805 [01:53<00:59, 16.18it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1846/2805 [01:53<00:58, 16.32it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1848/2805 [01:53<00:58, 16.37it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1850/2805 [01:53<00:58, 16.37it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1852/2805 [01:53<00:59, 16.08it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1854/2805 [01:53<00:59, 16.05it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1856/2805 [01:53<00:58, 16.11it/s]\u001b[A\n",
            "Eval:  66%|██████▌   | 1858/2805 [01:53<00:58, 16.24it/s]\u001b[A\n",
            "Eval:  66%|██████▋   | 1860/2805 [01:54<00:58, 16.20it/s]\u001b[A\n",
            "Eval:  66%|██████▋   | 1862/2805 [01:54<00:58, 16.25it/s]\u001b[A\n",
            "Eval:  66%|██████▋   | 1864/2805 [01:54<00:58, 16.18it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1866/2805 [01:54<00:58, 16.19it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1868/2805 [01:54<00:57, 16.17it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1870/2805 [01:54<00:57, 16.36it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1872/2805 [01:54<00:56, 16.42it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1874/2805 [01:54<00:56, 16.37it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1876/2805 [01:54<00:56, 16.41it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1878/2805 [01:55<00:56, 16.43it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1880/2805 [01:55<00:56, 16.45it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1882/2805 [01:55<00:56, 16.36it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1884/2805 [01:55<00:56, 16.43it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1886/2805 [01:55<00:56, 16.36it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1888/2805 [01:55<00:55, 16.46it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1890/2805 [01:55<00:55, 16.49it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 1892/2805 [01:55<00:55, 16.46it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1894/2805 [01:56<00:55, 16.43it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1896/2805 [01:56<00:55, 16.44it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1898/2805 [01:56<00:55, 16.40it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1900/2805 [01:56<00:55, 16.44it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1902/2805 [01:56<00:54, 16.45it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1904/2805 [01:56<00:54, 16.49it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1906/2805 [01:56<00:54, 16.52it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1908/2805 [01:56<00:54, 16.55it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1910/2805 [01:57<00:53, 16.59it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1912/2805 [01:57<00:54, 16.32it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1914/2805 [01:57<00:55, 16.12it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1916/2805 [01:57<00:55, 15.98it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1918/2805 [01:57<00:56, 15.83it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 1920/2805 [01:57<00:55, 15.84it/s]\u001b[A\n",
            "Eval:  69%|██████▊   | 1922/2805 [01:57<00:55, 15.79it/s]\u001b[A\n",
            "Eval:  69%|██████▊   | 1924/2805 [01:57<00:55, 15.96it/s]\u001b[A\n",
            "Eval:  69%|██████▊   | 1926/2805 [01:58<00:54, 16.08it/s]\u001b[A\n",
            "Eval:  69%|██████▊   | 1928/2805 [01:58<00:54, 16.15it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1930/2805 [01:58<00:54, 16.06it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1932/2805 [01:58<00:54, 16.09it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1934/2805 [01:58<00:53, 16.20it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1936/2805 [01:58<00:53, 16.21it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1938/2805 [01:58<00:53, 16.32it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1940/2805 [01:58<00:53, 16.09it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1942/2805 [01:59<00:53, 16.21it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1944/2805 [01:59<00:53, 15.96it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1946/2805 [01:59<00:54, 15.83it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 1948/2805 [01:59<00:53, 15.88it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1950/2805 [01:59<00:53, 16.09it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1952/2805 [01:59<00:52, 16.25it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1954/2805 [01:59<00:52, 16.32it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1956/2805 [01:59<00:51, 16.43it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1958/2805 [02:00<00:51, 16.40it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1960/2805 [02:00<00:52, 16.18it/s]\u001b[A\n",
            "Eval:  70%|██████▉   | 1962/2805 [02:00<00:52, 16.14it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1964/2805 [02:00<00:52, 15.95it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1966/2805 [02:00<00:52, 15.89it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1968/2805 [02:00<00:52, 15.90it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1970/2805 [02:00<00:52, 15.81it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1972/2805 [02:00<00:52, 15.97it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1974/2805 [02:01<00:51, 15.99it/s]\u001b[A\n",
            "Eval:  70%|███████   | 1976/2805 [02:01<00:51, 16.07it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1978/2805 [02:01<00:51, 16.05it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1980/2805 [02:01<00:51, 15.94it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1982/2805 [02:01<00:51, 16.10it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1984/2805 [02:01<00:51, 15.94it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1986/2805 [02:01<00:50, 16.08it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1988/2805 [02:01<00:50, 16.15it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1990/2805 [02:02<00:50, 16.16it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1992/2805 [02:02<00:50, 16.21it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1994/2805 [02:02<00:50, 16.21it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1996/2805 [02:02<00:49, 16.28it/s]\u001b[A\n",
            "Eval:  71%|███████   | 1998/2805 [02:02<00:49, 16.34it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 2000/2805 [02:02<00:49, 16.36it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 2002/2805 [02:02<00:48, 16.40it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 2004/2805 [02:02<00:48, 16.42it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2006/2805 [02:03<00:48, 16.49it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2008/2805 [02:03<00:48, 16.41it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2010/2805 [02:03<00:48, 16.40it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2012/2805 [02:03<00:49, 16.13it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2014/2805 [02:03<00:49, 16.10it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2016/2805 [02:03<00:48, 16.28it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2018/2805 [02:03<00:47, 16.43it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2020/2805 [02:03<00:47, 16.51it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2022/2805 [02:03<00:47, 16.47it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2024/2805 [02:04<00:47, 16.43it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2026/2805 [02:04<00:47, 16.43it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2028/2805 [02:04<00:47, 16.39it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2030/2805 [02:04<00:47, 16.44it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 2032/2805 [02:04<00:46, 16.45it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2034/2805 [02:04<00:46, 16.52it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2036/2805 [02:04<00:46, 16.57it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2038/2805 [02:04<00:46, 16.46it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2040/2805 [02:05<00:46, 16.42it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2042/2805 [02:05<00:46, 16.42it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2044/2805 [02:05<00:46, 16.40it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2046/2805 [02:05<00:46, 16.42it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2048/2805 [02:05<00:46, 16.37it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2050/2805 [02:05<00:45, 16.43it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2052/2805 [02:05<00:45, 16.50it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2054/2805 [02:05<00:45, 16.49it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2056/2805 [02:06<00:45, 16.44it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2058/2805 [02:06<00:45, 16.34it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 2060/2805 [02:06<00:45, 16.23it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 2062/2805 [02:06<00:45, 16.25it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 2064/2805 [02:06<00:45, 16.36it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 2066/2805 [02:06<00:45, 16.26it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 2068/2805 [02:06<00:45, 16.14it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2070/2805 [02:06<00:45, 16.14it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2072/2805 [02:07<00:45, 16.10it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2074/2805 [02:07<00:45, 16.13it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2076/2805 [02:07<00:45, 16.18it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2078/2805 [02:07<00:44, 16.19it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2080/2805 [02:07<00:44, 16.24it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2082/2805 [02:07<00:44, 16.29it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2084/2805 [02:07<00:43, 16.40it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2086/2805 [02:07<00:43, 16.42it/s]\u001b[A\n",
            "Eval:  74%|███████▍  | 2088/2805 [02:08<00:43, 16.41it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2090/2805 [02:08<00:43, 16.39it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2092/2805 [02:08<00:43, 16.40it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2094/2805 [02:08<00:43, 16.39it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2096/2805 [02:08<00:43, 16.42it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2098/2805 [02:08<00:43, 16.43it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2100/2805 [02:08<00:42, 16.42it/s]\u001b[A\n",
            "Eval:  75%|███████▍  | 2102/2805 [02:08<00:42, 16.44it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2104/2805 [02:08<00:42, 16.43it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2106/2805 [02:09<00:42, 16.43it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2108/2805 [02:09<00:42, 16.44it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2110/2805 [02:09<00:42, 16.46it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2112/2805 [02:09<00:42, 16.28it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2114/2805 [02:09<00:43, 16.02it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 2116/2805 [02:09<00:42, 16.10it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2118/2805 [02:09<00:42, 16.20it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2120/2805 [02:09<00:42, 16.19it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2122/2805 [02:10<00:42, 16.20it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2124/2805 [02:10<00:42, 16.17it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2126/2805 [02:10<00:41, 16.23it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2128/2805 [02:10<00:41, 16.20it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2130/2805 [02:10<00:41, 16.28it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2132/2805 [02:10<00:41, 16.38it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2134/2805 [02:10<00:41, 16.26it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2136/2805 [02:10<00:41, 16.26it/s]\u001b[A\n",
            "Eval:  76%|███████▌  | 2138/2805 [02:11<00:40, 16.44it/s]\u001b[A\n",
            "Eval:  76%|███████▋  | 2140/2805 [02:11<00:40, 16.32it/s]\u001b[A\n",
            "Eval:  76%|███████▋  | 2142/2805 [02:11<00:40, 16.40it/s]\u001b[A\n",
            "Eval:  76%|███████▋  | 2144/2805 [02:11<00:40, 16.49it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2146/2805 [02:11<00:39, 16.53it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2148/2805 [02:11<00:39, 16.48it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2150/2805 [02:11<00:39, 16.46it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2152/2805 [02:11<00:39, 16.48it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2154/2805 [02:12<00:39, 16.50it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2156/2805 [02:12<00:39, 16.45it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2158/2805 [02:12<00:39, 16.53it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2160/2805 [02:12<00:39, 16.36it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2162/2805 [02:12<00:39, 16.45it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2164/2805 [02:12<00:39, 16.35it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2166/2805 [02:12<00:38, 16.42it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2168/2805 [02:12<00:38, 16.50it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2170/2805 [02:13<00:39, 16.20it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 2172/2805 [02:13<00:39, 16.07it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2174/2805 [02:13<00:39, 16.15it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2176/2805 [02:13<00:39, 15.88it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2178/2805 [02:13<00:39, 15.85it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2180/2805 [02:13<00:39, 15.92it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2182/2805 [02:13<00:39, 15.93it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2184/2805 [02:13<00:38, 16.05it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2186/2805 [02:14<00:38, 15.98it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2188/2805 [02:14<00:38, 16.17it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2190/2805 [02:14<00:38, 16.10it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2192/2805 [02:14<00:37, 16.13it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2194/2805 [02:14<00:37, 16.09it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2196/2805 [02:14<00:37, 16.29it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2198/2805 [02:14<00:36, 16.44it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 2200/2805 [02:14<00:36, 16.45it/s]\u001b[A\n",
            "Eval:  79%|███████▊  | 2202/2805 [02:15<00:36, 16.48it/s]\u001b[A\n",
            "Eval:  79%|███████▊  | 2204/2805 [02:15<00:36, 16.46it/s]\u001b[A\n",
            "Eval:  79%|███████▊  | 2206/2805 [02:15<00:36, 16.35it/s]\u001b[A\n",
            "Eval:  79%|███████▊  | 2208/2805 [02:15<00:36, 16.39it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2210/2805 [02:15<00:36, 16.41it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2212/2805 [02:15<00:36, 16.45it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2214/2805 [02:15<00:36, 16.42it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2216/2805 [02:15<00:36, 16.19it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2218/2805 [02:15<00:36, 16.23it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2220/2805 [02:16<00:36, 16.13it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2222/2805 [02:16<00:36, 16.10it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2224/2805 [02:16<00:36, 15.88it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2226/2805 [02:16<00:35, 16.11it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 2228/2805 [02:16<00:35, 16.25it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2230/2805 [02:16<00:35, 16.24it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2232/2805 [02:16<00:35, 16.26it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2234/2805 [02:16<00:35, 16.29it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2236/2805 [02:17<00:34, 16.37it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2238/2805 [02:17<00:34, 16.35it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2240/2805 [02:17<00:34, 16.41it/s]\u001b[A\n",
            "Eval:  80%|███████▉  | 2242/2805 [02:17<00:34, 16.50it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2244/2805 [02:17<00:33, 16.53it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2246/2805 [02:17<00:33, 16.47it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2248/2805 [02:17<00:33, 16.42it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2250/2805 [02:17<00:33, 16.44it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2252/2805 [02:18<00:34, 16.22it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2254/2805 [02:18<00:34, 15.88it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2256/2805 [02:18<00:34, 16.01it/s]\u001b[A\n",
            "Eval:  80%|████████  | 2258/2805 [02:18<00:33, 16.10it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2260/2805 [02:18<00:33, 16.22it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2262/2805 [02:18<00:33, 16.24it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2264/2805 [02:18<00:33, 16.33it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2266/2805 [02:18<00:33, 16.19it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2268/2805 [02:19<00:33, 15.98it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2270/2805 [02:19<00:33, 16.05it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2272/2805 [02:19<00:33, 16.00it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2274/2805 [02:19<00:33, 16.01it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2276/2805 [02:19<00:32, 16.12it/s]\u001b[A\n",
            "Eval:  81%|████████  | 2278/2805 [02:19<00:32, 16.18it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 2280/2805 [02:19<00:32, 16.14it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 2282/2805 [02:19<00:32, 16.15it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 2284/2805 [02:20<00:31, 16.29it/s]\u001b[A\n",
            "Eval:  81%|████████▏ | 2286/2805 [02:20<00:31, 16.36it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2288/2805 [02:20<00:31, 16.43it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2290/2805 [02:20<00:31, 16.54it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2292/2805 [02:20<00:31, 16.53it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2294/2805 [02:20<00:31, 16.47it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2296/2805 [02:20<00:31, 16.22it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2298/2805 [02:20<00:31, 16.28it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2300/2805 [02:21<00:30, 16.33it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2302/2805 [02:21<00:30, 16.31it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2304/2805 [02:21<00:30, 16.46it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2306/2805 [02:21<00:30, 16.47it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2308/2805 [02:21<00:30, 16.49it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2310/2805 [02:21<00:30, 16.43it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2312/2805 [02:21<00:29, 16.46it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 2314/2805 [02:21<00:29, 16.45it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2316/2805 [02:22<00:29, 16.37it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2318/2805 [02:22<00:29, 16.30it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2320/2805 [02:22<00:29, 16.53it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2322/2805 [02:22<00:29, 16.33it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2324/2805 [02:22<00:29, 16.49it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2326/2805 [02:22<00:29, 16.47it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2328/2805 [02:22<00:29, 16.41it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2330/2805 [02:22<00:28, 16.45it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2332/2805 [02:22<00:28, 16.45it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2334/2805 [02:23<00:28, 16.27it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2336/2805 [02:23<00:28, 16.37it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2338/2805 [02:23<00:28, 16.39it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2340/2805 [02:23<00:28, 16.56it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 2342/2805 [02:23<00:27, 16.58it/s]\u001b[A\n",
            "Eval:  84%|████████▎ | 2344/2805 [02:23<00:27, 16.52it/s]\u001b[A\n",
            "Eval:  84%|████████▎ | 2346/2805 [02:23<00:28, 16.31it/s]\u001b[A\n",
            "Eval:  84%|████████▎ | 2348/2805 [02:23<00:28, 16.16it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2350/2805 [02:24<00:27, 16.26it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2352/2805 [02:24<00:27, 16.24it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2354/2805 [02:24<00:27, 16.32it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2356/2805 [02:24<00:27, 16.37it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2358/2805 [02:24<00:27, 16.09it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2360/2805 [02:24<00:27, 16.11it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2362/2805 [02:24<00:27, 16.26it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2364/2805 [02:24<00:27, 16.30it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2366/2805 [02:25<00:26, 16.39it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2368/2805 [02:25<00:26, 16.39it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 2370/2805 [02:25<00:26, 16.41it/s]\u001b[A\n",
            "Eval:  85%|████████▍ | 2372/2805 [02:25<00:26, 16.40it/s]\u001b[A\n",
            "Eval:  85%|████████▍ | 2374/2805 [02:25<00:26, 16.44it/s]\u001b[A\n",
            "Eval:  85%|████████▍ | 2376/2805 [02:25<00:26, 16.23it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QNGTxS2BNo2",
        "outputId": "6e75843b-07dc-49dd-e055-b1ce771bb547"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jul 10 15:26:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WfWyche42jT",
        "outputId": "f6fc3a28-9551-4153-ebee-c33812cf43bb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT_Yahoo  datasets  parameters\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}